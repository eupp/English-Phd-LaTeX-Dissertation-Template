\chapter{Обзор}
\label{ch:review}

В данной главе приводится введение в предметную область
данного диссертационного исследования --- слабые модели памяти.
Рассматриваются требования, предъявляемые к моделям памяти,
обсуждаются существующие модели памяти и их классификация.
Рассматриваются недостатки существующих моделей памяти
и открытые исследовательские вопросы.
Также вводятся необходимые математические формализмы,
используемые для описания семантики многопоточных программ
и слабых моделей памяти. 

\section{Слабые модели памяти}

Напомним, что в контексте данного исследования
моделью памяти называется формальная семантика
многопоточных программ, оперирующих с разделяемой памятью.
Одной из наиболее простых для понимания моделей памяти
является модель \emph{последовательной согласованности}
(\emph{sequential consistency})~\cite{Lamport:TC79}.
В рамках данной модели каждый допустимый
сценарий поведения многопоточной программы
является результатом поочередного исполнения
атомарных обращений к разделяемой памяти из параллельных потоков.

Рассмотрим, например, параллельную программу, показанную ниже.

\input{Dissertation/fig/dekker-ex}

Данная программа является упрощенной версией
алгоритма блокировки Деккера~\cite{Dijkstra:68}.
В этой программе два потока соревнуются за доступ к критической секции.
Каждый поток, для того чтобы обозначить свое намерение войти в критическую секцию,
устанавливает значение переменной $x$ или $y$ соответственно
\footnote{В данной работе разделяемые переменные
будем обозначать как $x$, $y$, $z$..., 
а локальные переменные как $r_1$, $r_2$, $r_3$...}.
Право войти в критическую секцию получает тот поток, 
который успеет прочитать значение переменной до его установки другим потоком.

В рамках модели последовательной согласованности
в результате выполнения данной программы 
либо один из потоков прочитает значение~\tcode{1}, а другой~\tcode{0}, 
либо оба прочитают значение~\tcode{1} (в этом случае ни один из потоков
не войдет в критическую секцию).
То есть в результате получим один из следующих исходов:
${[r_1=0, r_2=1]}$, ${[r_1=1,r_2=0]}$ или ${[r_1=1,r_2=1]}$. 
Данные сценарии поведения будем называть 
\emph{последовательно согласованными}.

Алгоритм Деккера полагается на тот факт, что оба 
потока не могут одновременно прочитать значение~\tcode{0}.
В противном случае не гарантируется свойство \emph{взаимного исключения}, 
то есть два потока могут одновременно войти в критическую секцию. 
Тем не менее на практике можно также наблюдать
сценарий поведения данной программы, нарушающий это предположение, 
то есть в результате которого имеем ${[r_1=0,r_2=0]}$.
Например, данный сценарий поведения можно наблюдать,
если перевести приведенный выше псевдокод алгоритма Деккера
на язык \CLANG, скомпилировать его с помощью \GCC
и запустить получившийся код на процессорах семейства \IntelX.

Подобные сценарии поведения, 
не укладывающиеся в модель последовательной согласованности, 
принято называть \emph{слабыми сценариями}.
Слабые сценарии поведения могут появляться 
в результате выполнения различных оптимизаций 
компилятором при сборке программы или процессором при ее исполнении. 
Например, в случае программы \ref{ex:Dekker}, оптимизатор может выполнить 
\emph{переупорядочивание независимых инструкций} 
записи в переменную $x$ и чтения из переменной $y$ в левом потоке.
Для оптимизированной версии программы сценарий поведения, 
ведущий к результату ${[r_1=0, r_2=0]}$, уже является последовательно согласованным.

Современные многопоточные системы 
как правило предоставляют \emph{слабые модели памяти},
то есть модели, допускающие слабые сценарии поведения,
поскольку более строгая модель последовательной согласованности
не допускает применение широкого спектра оптимизаций
и, следовательно, реализовация данной модели на практике
приводит к значительным накладным расходам%
~\cite{Marino-al:PLDI11,Singh-al:ISCA12,Liu-al:OOPSLA17,Liu-al:PLDI19}. 

Как было продемонстрировано выше на примере алгоритма Деккера, 
чтобы гарантировать корректность многопоточных программ
разрабочикам необходимо учитывать слабые сценарии поведения.
Таким образом, важно понимать, насколько слабую модель памяти
предоставляет многопоточная система, какие оптимизации 
допускаются этой моделью памяти и какие гарантии 
эта модель предлагает программисту. 

Далее в разделе \ref{sec:models-primitives} 
вводятся программные примитивы для работы с разделяемой памятью. 
В разделе \ref{sec:models-requirements} более подробно обсуждаются 
различные требования, предъявляемые к моделям памяти, 
а в разделе \ref{sec:models-classes} обсуждаются существующие модели и их классификация. 
Наконец в разделе \ref{sec:models-summary} приводится сравнение различных 
классов моделей памяти и обозначаются открытые исследовательские проблемы, 
некоторые из которых были решены в рамках данного исследования. 

\subsection{Программные примитивы предоставляемые моделью памяти}
\label{sec:models-primitives}

%% Краткое введение в область слабых моделей памяти, пример. 
%% Обоснование важности исследования этой области.  

\subsection{Требования к моделям памяти}
\label{sec:models-requirements}

Основные требования предъявлемые к моделям памяти,
их краткое описание и мотивация их введения:

\begin{itemize}
  \item Корректность компиляции.
  \item Корректность трансформаций программ.
  \item Предоставляемые гарантии для рассуждения о поведении программ.
    Здесь также будет сделан акцент на инструментах
    для верификации многопоточных программ. 
\end{itemize}

\subsection{Классы моделей памяти}
\label{sec:models-classes}

Рассмотрим программы \ref{ex:LB-nodep}, \ref{ex:LB-fakedep} и \ref{ex:LB-dep}, 
показанные ниже. \TODO{}

\input{Dissertation/fig/lb-ex}

Основные классы моделей памяти (по материалам обзорной статьи~\cite{Moiseenko-al:PCS21}).
Описание свойств этих классов и компромиссов в их дизайне
в соответствии с требованиями, предъявленными в предыдущем разделе. 

\subsection{Сравнение моделей памяти и открытые проблемы}
\label{sec:models-summary}

Подведение итога обзора моделей памяти.
Фрагмент сравнительной таблицы из обзорной статьи~\cite{Moiseenko-al:PCS21}.
Обозначение research gaps, которые закрывает данная диссертация, а именно:

\begin{itemize}
  \item классическая теория структур событий для моделей памяти
    сохраняющих программный порядок;
  \item корректность компиляции для модели \Wkm;
  \item автоматическая верификация многопоточных программ
    (model checking) в модели \WkmS.
\end{itemize}

\section{Формальная семантика параллельных программ и моделей памяти}

В этом разделе приводятся определения различных формализмов,
используемых для задания семантики многопоточных программ и моделей памяти.
В разделе \cref{sec:lts} дано определение \emph{систем помеченных переходов}
и \emph{операционных семантик с чередованием} 
(\emph{interleaving operational semanitcs}).
В разделе \cref{sec:pomsets-eventstruct} приводится альтернативный способ
задания семантики многопоточных программ без чередования 
(\emph{non-interleaving}) 
с помощью семантических доменов \emph{истинной конкурентности} 
(\emph{true concurrency}), а именно 
\emph{языков частично упорядоченных мультимножеств} и \emph{структур событий}.
В разделе \cref{sec:exec-graphs} вводится понятие графов сценариев исполнения
и аксиоматических моделей памяти, а также приводится краткое сравнение
графов сценариев исполнения и частично упорядоченных мультимножеств.
Наконец, в разделе \cref{sec:wkmo-eventstruct} вводится
специальный тип структур событий, используемых в модели \Wkm.

\subsection{Системы помеченных переходов}
\label{sec:lts}

Системы помеченных переходов являются традиционным 
способом задания операционной семантики. 
Системы помеченных переходов это (потенциально бесконечный) граф, 
вершины в котором представляют внутрение состояния системы, а
ребра соответствуют выполнению шага вычислений. 
Метка ребра задает видимый эффект выполения данного шага вычислений.
%% Множество трасс автомата задает его ``последовательную'' спецификацию, 
%% а список меток, индуцируемый трассой, определяет
%% наблюдаемое поведение автомата. 

\begin{definition}
  \label{def:lts}
  \emph{Система помеченных переходов} --- это тройка
    $\LTS \defeq \tup{\State, \Label, \TrRel}$, где 
  \begin{itemize}
    \item $\State$ --- множество состояний;
    \item $\Label$ --- множество меток, также называемое \emph{алфавитом};
    \item $R \subseteq L \times S \times S$ --- помеченное отношение перехода.
  \end{itemize}
  Для обозначения наличия перехода между состояниями используется следующая нотация:
    \[
    \begin{array}{lcr@{\hspace{3em}}lcr}
    \ltr[R]{\ell}{s}{s'} & \defeq & \step{\ell}{s}{s'} \in \TrRel                     &
    \tr[R]{s}{s'}        & \defeq & \exists \ell \ldotp \step{\ell}{s}{s'} \in \TrRel \\
    \end{array}
    \]
  \emph{Трассой} помеченной системой переходов называется чередующаяся последовательность  
  состояний $s_0, s_1, \ldots, s_n \in \Label$ 
  и меток $\ell_1, \ldots, \ell_n \in L$, 
  такая что выполняется условие
  $$s_0 \xrightarrow{\ell_1} s_1 \xrightarrow{\ell_2} s_2 \xrightarrow{\ell_3} \ldots \xrightarrow{\ell_n} s_n$$
  Язык, принимаемый системой переходов в начальном состоянии $s_0$ 
  это множество последовательностей слов над алфавитом $\Label$, 
  таких что для каждого слова существует соответствующая 
  трасса, начинающася в $s_0$:
  $$ \langof{\LTS, s_0} \defeq \set{ 
       \ell_1 \ldots \ell_n ~|~ \exists s_1, \ldots, s_n \ldotp 
       s_0 \xrightarrow{\ell_1} s_1 \xrightarrow{\ell_2} \ldots \xrightarrow{\ell_n} s_n
     } 
  $$
  
\end{definition}

\input{Dissertation/fig/lts-lang-ex}

На \cref{fig:lts-ex} показан пример системы помеченных переходов, 
а на \cref{fig:lang-ex} пример языка, 
принимаемаемого этой системой в состоянии $s_0$.

В рамках так называемой операционной семантики с чередованием
(interleaving semantics) поведение многопоточной программы
определяется как поочередное исполнение атомарных действий параллельных потоков.

\begin{definition}
  \label{def:lts-par}
  Параллельной композицией двух систем переходов $\LTS_1$ и $\LTS_2$
  будем называть систему переходов
  $\parlts{\LTS_1}{\LTS_2} \defeq \tup{\State_1 \times \State_2, \Label, \TrRel_{\parSymb}}$
  где $\TrRel_{\parSymb}$ определяется следующим образом:
  \begin{itemize}
    \item $\ltr[\TrRel_1]{\ell}{s_1}{s'_1}$ влечет
          $\ltr[\TrRel_{\parSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s'_1, s_2}}$, и
    \item $\ltr[\TrRel_2]{\ell}{s_2}{s'_2}$ влечет
          $\ltr[\TrRel_{\parSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s_1, s'_2}}$.
  \end{itemize}
\end{definition}

Если при этом потоки имеют доступ к общему ресурсу 
(например, разделяемой памяти), то в таком случае можно
семантику ресурса также задать с помощью системы переходов
а затем рассмотреть произведение параллельной композиции потоков и ресурса.  

\begin{definition}
  \label{def:lts-par}
  Произведением двух систем переходов $\LTS_1$ и $\LTS_2$
  будем называть систему переходов
  $\prodlts{\LTS_1}{\LTS_2} \defeq \tup{\State_1 \times \State_2, \Label, \TrRel_{\prodSymb}}$
  где $\TrRel_{\prodSymb}$ определяется следующим образом:
  \begin{itemize}
    \item $\ltr[\TrRel_{\prodSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s'_1, s'_2}}$ 
      тогда и только тогда, когда 
      $\ltr[\TrRel_1]{\ell}{s_1}{s'_1}$ и $\ltr[\TrRel_2]{\ell}{s_2}{s'_2}$.
  \end{itemize}
\end{definition}

Таким образом, если система помеченных переходов $\LTS_{\thrdSymb}$ 
задает семантику потоков, а система $\LTS_{\resSymb}$ --- 
семантику разделяемого ресурса, тогда 
$(\LTS_{\thrdSymb} \parSymb \dots \parSymb \LTS_{\thrdSymb}) \prodSymb \LTS_{\resSymb}$
задает семантику всей системы, состоящей из $n$ потоков и разделяемого ресурса.

\subsection{Языки помсетов и простые структуры событий}
\label{sec:pomsets-eventstruct}

Операционные семантики с чередованием представляют 
простой и интуитивно понятный подход для моделирования
многопоточных программ. Однако его недостаток заключается в том, 
что с ростом программы экспоненциально растет количество трасс, 
допустимых операционной семантикой. 

В попытке преодолеть эту проблему, исследователями 
были предложены различные альтернативные 
подходы к заданию семантики многопоточных программ, 
которые позволяют более компактно представить пространство 
возможных сценариев поведения таких программ. 
Данный класс семантик принято называть 
\emph{семантиками без чередования} (\emph{non-interleaving semantics})
или также \emph{истинно конкурентными семантиками}
(\emph{true concurrent semantics})~\cite{Nielsen:REX93}.
Из данного класса семантик в рамках 
данной диссертации интерес представляют 
\emph{языки частично упорядоченных мультимножеств}
(кратко --- языки помсетов)~\cite{Pratt:CONCUR84,Gischer:TCS88}, 
и \emph{структуры событий}~\cite{Winskel:86}.

Языки помеченных частично упорядоченных множеств является
обощением понятия обычных ``последовательных'' языков, 
то есть множества слов данного алфавита. 
Обобщение заключается в переходе от линейного порядка 
на символах алфавита в рамках слова к частичному порядку.
Частично упорядоченное множество соответствует одному
сценарию исполнения многопоточной программы.
Элементы этого множества представляют
атомарные шаги вычисления и называются \emph{событиями}.
Каждому событию ставится в соответствие семантическая \emph{метка} ---
символ заданного алфавита.
Если событие $e_1$ упорядочено перед ~$e_2$, $e_1 \ca e_2$, 
тогда считается что событие~$e_2$ в
сценарии исполнения программы зависит от события~$e_1$.
Если не выполняется ни $e_1 \ca e_2$ ни $e_2 \ca e_1$ 
тогда события $e_1$ и $e_2$ считаются параллельными, 
$e_1 \co e_2$. 

\begin{definition}
  \label{def:lposet}
  \emph{Помеченное частично упорядоченное множество} над множеством меток $\Label$, 
  это тройка $\tup{\Event, \lab, \ca}$, где 
  \begin{itemize}
    \item $\Event$ это множество \emph{событий};
    \item $\lab : \Event \fun \Label$ \emph{функция разметки событий};
    \item $\ca \subseteq \Event \times \Event$ это частичный порядок 
      \emph{причинно-следственной связи} между событиями. 
  \end{itemize}
  Множество всех помеченных частично упорядоченных множеств над алфавитом $\Label$
  будем обозначать как $\lPoset[\Label]$. 
\end{definition}

Отметим, что при работе c помеченными частично упорядоченными множествами
конкретные идентификаторы событий как правило неважны,
важна лишь их разметка и отношение причинно-следственной связи между ними.
Таким образом, с помеченными частично упорядоченными множествами 
работают по модулю переименования событий, то есть с точностью до изоморфизма.

\begin{definition}
  \label{def:lposet-morph}
  Рассмотрим $p, q \in \lPoset[\Label]$. Функция $f : E_p \fun E_q$ называется:
  \begin{itemize}
    \item \emph{сохраняющей метки} если ${\lab_q(f(e)) = \lab_p(e)}$;
    \item \emph{сохраняющей порядок} если ${e_1 \ca_p e_2}$ влечет ${f(e_1) \ca_q f(e_2)}$;
    \item \emph{вкладывающей порядок} если ${e_1 \ca_p e_2}$ тогда и только тогда, когда ${f(e_1) \ca_q f(e_2)}$.
  \end{itemize}
  \emph{Гомоморфизмом} частично упорядоченных помеченных множеств называется
  функция, сохраняющая метки и порядок. Если более того эта фунцкия
  биективна и вкладываюет порядок, то она называется изоморфизмом.
  Запись $p \iso q$ означает что $p$ и $q$ изоморфны,
  то есть существует изоморфная функция между носителями $p$ и $q$.
\end{definition}

\begin{definition}
  \label{def:pomset}
  Помеченные частично упорядоченные мультимножества, 
  или, кратко, \emph{помсеты} (от англ. \emph{partially ordered multiset, pomset}), 
  это классы помеченных частично упорядоченных множеств по модулю изоморфизма: 
  $${\Pom[\Label] \defeq \lPoset[\Label] / {\iso}}.$$ 
  Язык помсетов --- это множество помсетов: 
  $${\Pomlang[\Label] \defeq \pwset{\Pom[\Label]}}.$$ 
\end{definition}

\input{Dissertation/fig/pom-es-ex}

На \cref{fig:pom-ex} можно видеть пример языка помсетов. 
Этот язык помсетов кодирует обычный язык, показанный \cref{fig:lang-ex}, 
так как каждое слово из обычного языка является дополнением некоторого 
частичного упорядоченного множества из языка помcетов
до линейно упорядоченного множества. 
Формально, связь языка помсетов и обычного языка можно установить 
с помощью понятия \emph{линеаризации помсета}.

\begin{definition}
  \label{def:pomset-subs}
  Помсет $p$ \emph{поглощается} $q$, $p \subs q$, 
  если существует биективный гомоморфизм из $q$ в $p$.
  В таком случае также говорят, что $p$ более упорядочено чем $q$.
\end{definition}

\begin{definition}
  \label{def:pomset-lin}
  Помсет $p$ является линеаризацией $q$, 
  что обозначается как $p \in \Lin{q}$,
  если $p$ является линейно упорядоченным и 
  поглощается $q$, $p \subs q$.
  Линеаризация языка помсетов $P$ определяется 
  как объединение линеаризации всех входящих в язык помсетов:
  $$ \Lin{P} \defeq \bigcup_{p \in P}\Lin{p} $$
  Наконец, можно сказать что язык помсетов $P \in \Pomlang[\Label]$
  соответствует обычному языку $L \in \Lang{\Label}$, если $\Lin{P} = L$.
\end{definition}

Множество помсетов можно объединить в одну \emph{структуру событий},
и таким образом представить язык помсетов как одно частично упорядоченное множество.
Существует множество видов структур событий~\cite{}, 
в контексте данной работы будем рассматривать класс \emph{простых структур событий}.
Везде далее под термином \emph{структура событий} будем подразумевать 
именно простую структуру событий, если иное не сказано явно. 

По сравнению с помеченным частично упорядоченным множеством, 
простые структуры событий позволяют дополнительно выразить тот факт, 
что два события $e_1$ и $e_2$ находятся в конфликте.
Это означает, что эти два события не могут одновременно 
принадлежать одному сценарию исполнения программы. 

\begin{definition}
  \label{def:lposet-dwfin}
  Будем говорить, что помеченное частично упорядоченное множество 
  $p = \tup{\Event, \lab, \ca}$ является \emph{префикс конечным} 
  если каждое событие имеет конечное число предшественников, 
  то есть для любого $e \in \Event$ множество 
  $\dwset{e} \defeq \set{e' ~|~ e' \ca e}$ конечно.
\end{definition}

\begin{definition}
  \label{def:prime-es}
  \emph{Простая структура событий с бинарным конфликтом} над множеством меток $\Label$ 
  это кортеж $\tup{\Event, \lab, \ca, \cf}$, где 
  $\tup{\Event, \lab, \ca}$ это префикс-конечное помеченное 
  частично упорядоченное множество, 
  а $\cf \suq \Event \times \Event$ --- это \emph{бинарное отношение конфликта}, 
  которое является иррефлексивным, симметричным и 
  удовлетворяет свойству \emph{наследственности}:
  $$ e_1 \cf e_2 ~\text{и}~ e_2 \ca e_3 ~\text{влечет}~ e_1 \cf e_3.$$
\end{definition}

Отметим, что зачастую язык помсетов может иметь более сложную структуру 
конфликтности между событиями, которая не может быть сведена 
к бинарному конфликту между парой событий. 
В таком случае рассматривают простые структуры событий более общего вида. 

\begin{definition}
  \label{def:prime-cons-es}
  \emph{Простая структура событий с предикатом консистентости} над множеством меток $\Label$ 
  это кортеж $\tup{\Event, \lab, \ca, \Cons}$, где 
  $\tup{\Event, \lab, \ca}$ это префикс-конечное помеченное 
  частично упорядоченное множество, 
  а $\Cons \suq \pwfset{\Event}$ --- это \emph{предикат консистентности}, 
  который должен удовлетворять следующим условиям:
  \begin{enumerate}
    \item \label{ax:prime-cons-emp}
      $\emptyset \in \Cons$,
    \item \label{ax:prime-cons-subs}
      $X \subseteq Y$ и $Y \in \Cons$ влечет $X \in \Cons$,
    \item \label{ax:prime-cons-ca}
      $e_1 \ca e_2$ и $\set{e_2} \cup X \in \Cons$ 
      влечет $\set{e_1} \cup X \in \Cons$.
  \end{enumerate}
\end{definition}

Можно видеть, что простые структуры событий с бинарным конфликтом
являются частным случаем простых структур событий 
с предикатом консистентности. 
Действительно, для простой структуры событий с бинарным конфликтом
можно определить предикат консистентности следующим образом:
$$X \in \Cons \iff \forall e_1~e_2 \in X \ldotp \neg e_1 \cf e_2.$$

Наконец, формально определим язык помсетов, порождаемый структурой событий. 

\begin{definition}
  \label{def:es-cfg}
  Пусть $S = \tup{\Event, \lab, \ca, \Cons}$ простая структура событий 
  с предикатом консистентности. Тогда подмножество событий 
  $X \suq \Event$ называется \emph{конфигурацией} структуры $S$ 
  если оно является префикс-замкнутым, а все его конечные подмножества 
  являются консистентными, то есть 
  \begin{itemize}
    \item $\dwset{X} \defeq {e' ~|~ \exists e \in X \ldotp~ e' \ca e } \suq X$, 
    \item $Y \finsubseteq X$ implies $Y \in \Cons$.
  \end{itemize}
  Будем обозначать как $\Cfg{S}$ множество всех конфигураций $S$.
\end{definition}

\begin{definition}
  \label{def:es-pomlang}
  Язык помсетов, порождаемый структурой событий $S = \tup{\Event, \lab, \ca, \Cons}$, 
  определяется следующим образом:
  $$ \pomlang{S} \defeq \set{p ~|~ \exists X \in \Cfg{S} \ldotp p = S\rst{X} }$$
  где $S\rst{X} \defeq {X, \lab\rst{X}, \ca\rst{X}}$ это сужение 
  структуры событий $S$ на консистентное подмножество событий $X$.
\end{definition}

\subsection{Графы сценариев исполнения}
\label{sec:exec-graphs}

Далее перейдем к описанию формализмов, используемых для
формального определения моделей памяти.

Напомним, что под моделью памяти понимается
семантика многопоточной системы, оперирующей с разделяемой памятью.
Поэтому, как уже упоминалось в \cref{sec:lts},
модель памяти можно определить в терминах операционной семантики.
В таком случае система переходов
$(\LTS_{\thrdSymb} \parSymb \dots \parSymb \LTS_{\thrdSymb}) \prodSymb \LTS_{\memSymb}$
будет описывать многопоточную систему, состояющую из $n$ потоков
и разделямой памяти, где $\LTS_{\thrdSymb}$ --- это система переходов,
описывающая поведение потоков, а $\LTS_{\memSymb}$ --- система переходов,
описывающая поведение разделяемой памяти. 

Как уже отмечалось, в контексте моделирования
многопоточных систем одним из недостатков подхода,
основанного на операционной семантике, 
является экспоненциально рост количество трасс системы.
В контексте слабых моделей памяти у данного подхода
также есть и другой недостаток.
Проблема заключается в том, что для кодирования каждой
отдельной модели памяти необходимо разработать
собственное представление этой модели памяти 
в терминах системы переходов $\LTS_{\memSymb}$.
При этом такая система может быть устроено
достаточно сложным образом и требовать моделирования
множества различных структур данных, например,
буферов операций, очередей сообщений,
многоуровневых кэшей и так далее.  

Поэтому для спецификации моделей памяти
зачастую используют альтернативный \emph{аксиоматический стиль}.
В аксиоматическом стиле задано большинство моделей
современных мультипроцессоров, например,
\Intel~\cite{Sewell-al:CACM10}, 
\POWER~\cite{Sarkar-al:PLDI11,Alglave-al:TOPLAS14}),
\ARM~\cite{Pulte-al:POPL18,Alglave-al:TOPLAS14}),
и некоторых языков программирования,
например, \OCaml~\cite{Dolan-al:PLDI18}, \JS~\cite{Watt-al:PLDI2020}.

Модель памяти в аксиоматическом стиле
определяется как множество консистентных 
\emph{графов сценариев исполнения} (\emph{execution graphs}).
В этом графе вершинами являются атомарные события,
а ребра формируют различные отношения между этими событиями.
Графы сценариев исполнения похожи на помсеты,
главное отличие между ними заключается в том, что 
помсет состоит из единственного
отношения причинно-следственной связи, 
а граф сценариев исполнения состоит из
нескольких отношений, наделенных различной семантикой.
Например, отношение \emph{программного порядка} (\emph{program order}) $\lPO$ 
задает порядок, в котором выполняются события в каждом потоке,
а отношение \emph{читает-из} (\emph{reads-from}) $\lRF$, 
для каждого события записи указывает 
какие события чтения выполняют операцию чтения из него. 
На Рис.\cref{fig:LB-nodep-execs} показаны примеры графов сценариев исполнения 
соответствующих программе \ref{ex:LB-nodep}.

\input{Dissertation/fig/execs-ex}

Далее введем формальное определение графов сценариев исполнения.
Но сначала необходимо также ввести тип семантических меток (алфавита)
для описания абстракции разделяемой памяти.

\begin{definition}
  \label{def:mem-aux}
  Введем следующие множества:
  \begin{itemize}
    \item $\Tid \suq \N$ обозначает множество \emph{идентификаторов потоков}, 
      а поток с идентификатором $t_0 \defeq 0$
      обозначает выделенный \emph{инициализирующий} поток;
    \item $\Loc$ обозначает множество \emph{разделяемых переменных} 
      (или \emph{локаций});
    \item $\Mod \defeq \set{\na, \rlx, \acq, \rel, \acqrel, \sco}$
      обозначает множество \emph{режимов доступа} (\emph{access modes})
      к разделяемым переменным;
    \item $\Val$ обозначает множество возможных \emph{значений}. 
  \end{itemize}  
\end{definition}

\begin{definition}
  \label{def:mem-lab}
  Определим множество меток $\MemLab$, 
  соответствующих абстракции разделяемой памяти. 
  Метка $l \in \MemLab$ принимает одну из следующих форм:
  \begin{itemize}
    \item $\rlab{o}{x}{v}$ --- метка операции чтения значения $v$ из переменной $x$, 
      аннотированная режимом доступа $o$;
    \item $\wlab{o}{x}{v}$ --- метка операции записи значения $v$ в переменную $x$, 
      аннотированная режимом доступа $o$;
    \item $\lF^o$ --- метка операции барьера, аннотированная режимом $o$.
  \end{itemize}
  Если у метки опущен режим доступа, то будем считать что 
  она аннотирована режимом $\rlx$.
\end{definition}

\begin{definition}
  \label{def:exec-graph}
  \emph{Граф сценария исполнения} (\emph{execution graph}) $G$ 
  это кортеж $\tup{\lE, \lLAB, \lPO, \lRMW, \lRF, \lCO}$.
  Компоненты этого кортежа определены следующим образом.
  \begin{itemize}

    \item $\lE \suq \N$ --- это множество событий.

    \item $\lTID : \lE \fun \Tid$ --- это функция, 
      которая присваивает каждому событию идентификатор потока.
      Множество событий, принадлежащих инициализирующему потоку,
      определяется как ${\lEi \defeq \set{e \in \lE \sth \lTID(e) = t_0}}$.

    \item $\lLAB : \lE \fun \MemLab$ --- это функция, 
      которая назначает каждому событию метку. 
      Данная функция также индуцирует частично определенные функции
      $\lTYP$, $\lLOC$, $\lMOD$, $\lVAL$, которые возвращают
      тип, локацию, режим доступа и значение метки соответственно. 
      Также положим, что $\lR$, $\lW$ и $\lF$ обозначают подмножества 
      событий с меткой операции чтения, записи и барьера соответственно.

    \item $\lPO \suq \lE \times \lE$ --- это отношение 
      \emph{программного порядка} (\emph{program order}).
      Это отношение строгого частичного порядка на событиях, 
      которое полностью упорядочивает все события внутри одного потока
      согласно потоку управления программы. 
      Дополнительно полагается, что инициализирующие события $\lEi$ 
      упорядочены программным порядоком раньше всех других событий.
      Также введем отношение \emph{непосредственного программного порядка}
      (\emph{immediate program order}): 
      будем считать событие $e_1$ непосредственным $\lPO$-предшественником 
      события $e_2$ если $e_1$ предшествует $e_2$ 
      и между ними нет других событий.
      \begin{equation*}
        \lPOimm \defeq \lPO \setminus (\lPO \seqc \lPO)
      \end{equation*}

    \item $\lRMW \suq \lRex \seqc \lPOimm \cap \lEQLOC \seqc \lWex$ ---
      отношение соединяющие \emph{атомарные пары событий чтения-записи}. 
      Если $\tup{r, w} \in \lRMW$ тогда считается, что данная пара событий
      возникла в ходе исполнения одной инструкции атомарного чтения-записи, 
      например, инструкции \emph{атомарного инкремента} (\emph{fetch-and-add}, \FADD), 
      или инструкции \emph{атомарного сравнения с обменом} 
      (\emph{compare-and-swap}, \CAS).

    \item $\lRF \suq [\lW] \seqc \lEQLOC \cap \lEQVAL \seqc [\lR]$ --- отношение 
      \emph{читает-из} (\emph{reads-from}). 
      Это отношение связывает событие-запись с событиями-чтениями, 
      которые выполняют операцию чтения из него. 
      Для каждого события чтения должно существовать 
      событие записи, из которого выполняется чтение: 
      $$ r \in \lR \implies \exists w \in \lW \ldotp \tup{w, r} \in \lRF.$$
      Более того, каждое событие чтения может быть связано только с одним событием записи:
      $$ \tup{w_1,r} \in \lRF \wedge \tup{w_2,r} \in \lRF \implies w_1 = w_2.$$

      Дополнительно будем рассматривать внутреннею (\emph{internal}) 
      и внешнюю (\emph{external}) $\lRFE$ версию отношения ``читает-из''
      (обозначается как $\lRFI$ и $\lRFE$ соответcтвенно), 
      в зависимости от того принадлежит ли пара событий записи и чтения
      одному потоку или разным потокам.
      \[\def\arraystretch{1}
       \begin{array}{c@{\qquad}c@{\qquad}c@{\qquad}c}
         \lRFI \defeq \lRF \cap \lPO      &
         \lRFE \defeq \lRF \setminus \lPO
       \end{array}
      \]

    \item $\lCO \suq [\lW] \seqc \lEQLOC \seqc [\lW]$ --- это отношение 
      \emph{когерентности}. Это отношение строгого частичного порядка на событиях, 
      которое полностью упорядочивает все операции записи в одну локацию. 
      Это отношение представляет порядок, в котором операции записи 
      продвигаются в основную память и становятся видимы другим потокам. 
      \begin{equation*}
        \forall w_1, w_2 \in \lW \ldotp~ 
          \lLOC(w_1) = \lLOC(w_2) \implies \tup{w_1, w_2} \in \lCO \cup \lCO^{-1}
      \end{equation*}
      По аналогии с отношением ``читает-из'' также определим
      внутреннею и внешнюю версии отношения когерентности.
      \[\def\arraystretch{1}
       \begin{array}{c@{\qquad}c@{\qquad}c@{\qquad}c}
         \lCOI \defeq \lCO \cap \lPO      &
         \lCOE \defeq \lCO \setminus \lPO
       \end{array}
      \]

  \end{itemize}

  Множество всех графов сценариев исполнения будем обозначать как~$\ExecG$.
\end{definition}

\begin{definition}
  \label{def:ax-memory-model}
  \emph{Аксиоматическая модель памяти} (\emph{axiomatic memory model}) $M$ 
  задается как подмножество графов сценариев исполнения: $M \suq \ExecG$.
  Граф $G$ называется \emph{консистентым} с точки зрения модели $M$, 
  или просто $M$-\emph{консистентым}, если $G \in M$.
\end{definition}

Модели памяти, сохраняющие программный порядок, накладывают 
ограничение консистентности требующее, чтобы объединение 
отношений программного порядка и ``читает-из'' было ацикличным. 

\begin{definition}
Будем говорить, что граф сценария исполнения $G$ 
\emph{сохраняет программный порядок}, если выполняются следующее условие: 
\begin{itemize}
  \item $\lPO \cup \lRF$ является ацикличным отношением.
    \labelAxiom{$\lPORF$-acyclic}{ax:porf-acyc}
\end{itemize}
Обозначим множество всех таких графов как $\PorfExecG$.
Также будем говорить, что модель памяти $M$, 
заданная в аксиоматическом стиле, сохраняет программный порядок, 
если любой $M$-консистентный граф сохраняет программный порядок, 
то есть ${M \suq \PorfExecG}$.
\end{definition}

Например, среди графов, показанных на Рис.\cref{fig:LB-nodep-execs}, 
графы \circledb{A}, \circledb{B} и \circledb{C} сохраняют программный порядок, 
а граф \circledb{D} --- нет, так как он содержит $\lPO \cup \lRF$ цикл.
Таким образом, сценарий исполнения программы \ref{ex:LB-nodep},
соответствующий графу \circledb{D},
и в результате которого в локальные переменные $a$ и $b$ записано значение $1$,
запрещен моделями памяти, сохраняющими программный порядок.

Модели памяти, сохраняющие синтаксические зависимости, 
могут допускать некоторые $\lPO \cup \lRF$ цикличные графы. 
Данные модели гарантируют сохранение порядка между событиями
одного потока только если они связаны отношением 
\emph{сохраняемого программного порядка} (\emph{preserved program order}) $\lPPO$, 
которое является подмножеством отношения программного порядка $\lPO$. 
Отношение сохраняемого программного порядка
строится с помощью отношения \emph{синтаксических зависимостей} между событиями, 
данное отношение включает отношения зависимости по данным, по управлению, и другие. 

\begin{definition}
  \label{def:imm-exec-graph}
  \emph{Расширенным графом сценария исполнения} будем называть
  обычный граф сценария исполнения (\cref{def:exec-graph}), дополненный отношениями 
  \emph{зависимости по данным} (\emph{data dependency}) $\lDATA$, 
  \emph{зависимости по потоку управления} (\emph{control dependency}) $\lCTRL$, 
  \emph{зависимости по целевому адресу} (\emph{address dependency}) $\lADDR$, 
  и \emph{зависимость по операции \CAS} (\emph{\CAS dependency}) $\lRMWDEP$.
\end{definition}

\input{Dissertation/fig/lb-execs}

В контексте моделей памяти, сохраняющих синтаксические зависимости,
под графом сценария исполнения будем подразумевать расширенный граф, 
который дополнен отношениями зависимости. 

Точное определение сохраняемого программного порядка может 
варьироваться в зависимости от конкретной модели памяти, 
но как правило оно включает как минимум объединение 
отношений зависимости, представленных выше. 
Далее модели памяти, сохраняющие синтаксические зависимости, 
накладывают ограничение консистентности требующее, чтобы объединение 
отношений сохраняемого программного порядка и 
внешнего отношения ``читает-из'' было ацикличным. 

\begin{definition}
Будем говорить, что граф сценария исполнения $G$ 
\emph{сохраняет синтаксические зависимости}, если выполняются следующие условия: 
\begin{itemize}
  \item $\lDEPS \suq \lPPO$;
    \labelAxiom{$\lPPO$-deps}{ax:ppo-deps}
  \item $\lPPO \cup \lRFE$ является ацикличным отношением.
    \labelAxiom{$\lPPORF$-acyclic}{ax:pporf-acyc}
\end{itemize}
Обозначим множество всех таких графов как $\PporfExecG$.
Также будем говорить, что модель памяти $M$, 
заданная в аксиоматическом стиле, сохраняет программный порядок, 
если любой $M$-консистентный граф сохраняет программный порядок, 
то есть ${M \suq \PporfExecG}$.
\end{definition}

Рассмотрим, например, пару $\lPO \cup \lRF$ цикличных графов, 
изображенных на Рис.\cref{fig:LB-ppo-execs}.
Данные графы соответствуют сценарию исполнения 
с результатом $a = b = 1$. 
Отметим, что при этом граф, показанный на 
Рис.\cref{fig:LB-nodep-ppo-exec}, является $\lPPO \cup \lRFE$
ацикличным, а граф на Рис.\cref{fig:LB-dep-ppo-exec} содержит такой цикл. 
Это объясняется тем, что в программу \ref{ex:LB-nodep} инстукции 
в левом потоке не связаны зависистью по данным, 
а в программах \ref{ex:LB-fakedep}~и~\ref{ex:LB-dep}
инструкции в обоих потоках связаны зависистью по данным. 
Таким образом, модели памяти, сохраняющие синтаксические зависимости, 
допускают сценарию исполнения с результатом $a = b = 1$ 
для программы \ref{ex:LB-nodep}, 
но не для программ \ref{ex:LB-fakedep}~и~\ref{ex:LB-dep}. 

%% \begin{definition}
%%   \label{def:imm-deps-rel}
%%   Для расширенного графа сценария исполнения определим 
%%   объединенное отношение \emph{зависимости} (\emph{dependency}) 
%%   следующим образом:
%%   $$ \lDEPS \defeq \lDATA \cup \lCTRL \cup \lADDR \seq \lPO^? \cup \lRMWDEP. $$
%% \end{definition}

%% \begin{definition}
%%   \label{def:imm-deps-rel}
%%   Для расширенного графа сценария исполнения определим 
%%   объединенное отношение \emph{зависимости} (\emph{dependency}) 
%%   следующим образом:
%%   $$ \lDEPS \defeq \lDATA \cup \lCTRL \cup \lADDR \seq \lPO^? \cup \lRMWDEP. $$
%% \end{definition}

\subsection{Структуры событий в модели \Wkm}
\label{sec:wkmo-eventstruct}

Определение класса структур событий, использующихся в модели \Wkm.
