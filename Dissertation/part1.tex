\chapter{Обзор}
\label{ch:review}

В данной главе приводится введение в предметную область
данного диссертационного исследования --- слабые модели памяти.
Рассматриваются требования, предъявляемые к моделям памяти,
обсуждаются существующие модели памяти и их классификация.
Рассматриваются недостатки существующих моделей памяти
и открытые исследовательские вопросы.
Также вводятся необходимые математические формализмы,
используемые для описания семантики многопоточных программ
и слабых моделей памяти. 

\section{Слабые модели памяти}
\label{sec:models-intro}

Напомним, что в контексте данного исследования
моделью памяти называется формальная семантика
многопоточных программ, оперирующих с разделяемой памятью.
В данной работе будем преимущественно говорить о моделях памяти 
высокоуровневых языков программирования~\cite{Moiseenko-al:PCS21}, 
таких как, например, \CPP, \Java и другие. 

Одной из наиболее простых для понимания моделей памяти
является модель \emph{последовательной согласованности}
(\emph{sequential consistency})~\cite{Lamport:TC79}.
В рамках данной модели каждый допустимый
сценарий поведения многопоточной программы
является результатом поочередного исполнения
атомарных обращений к разделяемой памяти из параллельных потоков.

Рассмотрим, например, параллельную программу, показанную ниже.

\input{Dissertation/fig/dekker-ex}

Данная программа является упрощенной версией
алгоритма блокировки Деккера~\cite{Dijkstra:68}.
В этой программе два потока соревнуются за доступ к критической секции.
Каждый поток, для того чтобы обозначить свое намерение войти в критическую секцию,
устанавливает значение переменной $x$ или $y$ соответственно
\footnote{В данной работе разделяемые переменные
будем обозначать как $x$, $y$, $z$..., 
а локальные переменные как $r_1$, $r_2$, $r_3$...}.
Право войти в критическую секцию получает тот поток, 
который успеет прочитать значение переменной до его установки другим потоком.

В рамках модели последовательной согласованности
в результате выполнения данной программы 
либо один из потоков прочитает значение~\tcode{1}, а другой~\tcode{0}, 
либо оба прочитают значение~\tcode{1} (в этом случае ни один из потоков
не войдет в критическую секцию).
То есть в результате получим один из следующих исходов:
${[r_1=0, r_2=1]}$, ${[r_1=1,r_2=0]}$ или ${[r_1=1,r_2=1]}$. 
Данные сценарии поведения будем называть 
\emph{последовательно согласованными}.

Алгоритм Деккера полагается на тот факт, что оба 
потока не могут одновременно прочитать значение~\tcode{0}.
В противном случае не гарантируется свойство \emph{взаимного исключения}, 
то есть два потока могут одновременно войти в критическую секцию. 
Тем не менее на практике можно также наблюдать
сценарий поведения данной программы, нарушающий это предположение, 
то есть в результате которого имеем ${[r_1=0,r_2=0]}$.
Например, данный сценарий поведения можно наблюдать,
если перевести приведенный выше псевдокод алгоритма Деккера
на язык \CLANG, скомпилировать его с помощью \GCC
и запустить получившийся код на процессорах семейства \IntelX.

Подобные сценарии поведения, 
не укладывающиеся в модель последовательной согласованности, 
принято называть \emph{слабыми сценариями}.
Слабые сценарии поведения могут появляться 
в результате выполнения различных оптимизаций 
компилятором при сборке программы или процессором при ее исполнении. 
Например, в случае программы \ref{ex:Dekker}, оптимизатор может выполнить 
\emph{переупорядочивание независимых инструкций} 
записи в переменную $x$ и чтения из переменной $y$ в левом потоке.
Для оптимизированной версии программы сценарий поведения, 
ведущий к результату ${[r_1=0, r_2=0]}$, уже является последовательно согласованным.

Современные многопоточные языки программирования 
как правило предоставляют \emph{слабые модели памяти},
то есть модели, допускающие слабые сценарии поведения,
поскольку более строгая модель последовательной согласованности
не допускает применение широкого спектра оптимизаций
и, следовательно, реализовация данной модели на практике
приводит к значительным накладным расходам%
~\cite{Marino-al:PLDI11,Singh-al:ISCA12,Liu-al:OOPSLA17,Liu-al:PLDI19}. 

Как было продемонстрировано выше на примере алгоритма Деккера, 
чтобы гарантировать корректность многопоточных программ
разрабочикам необходимо учитывать слабые сценарии поведения.
Таким образом, важно понимать, насколько слабую модель памяти
предоставляет язык программирования, какие оптимизации 
допускаются этой моделью памяти и какие гарантии 
эта модель предлагает программисту. 

Далее в разделе \ref{sec:models-primitives} 
вводятся программные примитивы для работы с разделяемой памятью. 
В разделе \ref{sec:models-requirements} более подробно обсуждаются 
различные требования, предъявляемые к моделям памяти, 
а в разделе \ref{sec:models-classes} обсуждаются существующие модели и их классификация. 
Наконец в разделе \ref{sec:models-summary} приводится сравнение различных 
классов моделей памяти и обозначаются открытые исследовательские проблемы, 
некоторые из которых были решены в рамках данного 
диссертационного исследования. 

\subsection{Программные примитивы предоставляемые моделью памяти}
\label{sec:models-primitives}

В рамках данного исследования будем считать, что
разделяемая память представляет собой отображение
из адресов переменных\footnote{В данной работе адрес переменной 
также иногда будем называть \emph{локацией}.} в их значения. 
Таким образом, будем подразумевать, 
что разделяемая память состоит из взаимно непересекающихся, 
типизированных адресуемых ячеек памяти%
\footnote{В теории моделей памяти также иногда определяют 
разделяемую память как нетипизированную последовательность байт, 
допускающую обращения \emph{смешанного размера} (\emph{mixed-size accesses}). 
В контексте данной работы смешанные обращения не рассматриваются.}

Основные операции, которые предоставляет абстракция разделяемой памяти --- 
это операция записи в разделяемую переменную и операция чтения из разделяемой переменной. 
Также, будем считать, что разделяемая память предоставляет атомарные операции 
\emph{чтения-модификации-записи} (\emph{read-modify-write}), 
в частности, операцию сравнения и замены (\emph{compare-and-swap}, \CAS), 
операцию атомарного обмена (\emph{exchange}, \EXCHG) 
и операцию атомарного инкремента (\emph{fetch-and-add}, \FADD).
Операция сравнения и замены атомарно выполняет сравнение 
текущего и ожидаемого значений переменной и в случае 
их совпадения заменяет значение переменной на желаемое.
Операция обмена атомарно заменяет значение переменной 
и возвращает ее прежнее значение. 
Наконец, операция атомарного инкремента прибавляет 
к значению переменной заданную величину и
возвращает ее значение до модификации.
Все инструкции обращения к разделяемой памяти 
приведены на Рис.\ref{fig:primitives}. 

\input{Dissertation/fig/primitives}

Помимо этого, модели памяти, как правило, различают 
несколько видов обращений к разделяемой памяти и позволяют 
программисту аннотировать эти обращения 
\emph{режимом доступа} (\emph{access mode}).
Режимы доступа отличаются гарантиями, 
которые они предоставляют пользователю. 
Выделяют следующие режимы доступа: 
\emph{неатомарный режим} (\emph{non-atomic}), 
\emph{ослабленный режим} (\emph{relaxed} или \emph{opaque} в терминологии \Java),
режим \emph{захвата} (\emph{acquire}), 
режим \emph{освобождения} (\emph{release}), 
их комбинированный режим \emph{захвата-освобождения} (\emph{acquire-release}), 
а также \emph{последовательно согласованный режим} 
(\emph{sequentially consistent} или \emph{volatile} в \Java).
Эти режимы обозначаются как $\na$, $\rlx$, $\acq$, $\rel$, $\acqrel$ и $\sco$ соответственно.
При этом режим $\acq$ применим только к операциям чтения,
а режим $\rel$ --- только к операциям записи.
Режимы обращения упорядочены согласно строгости предоставляемых гарантий, 
как показано на следующей диаграмме. 

\input{Dissertation/fig/modes}

Неатомарные обращения, аннотированные режимом $\na$, 
не предполагается использовать для конкурентного доступа 
к разделяемой переменной из параллельных потоков программы. 
В зависимости от конкретного языка программирования
конкурентные неатомарные обращения либо полностью запрещены
(например, в \Haskell~\cite{Vollmer-al:PPoPP17} и \Rust~\cite{RustBook:19}), 
либо могут приводить к неопределенному поведению
(например, в \CPP~\cite{Batty-al:POPL11}),
либо не предоставляют практический никаких гарантий о порядке,
в котором потоки могут наблюдать эти обращения
(например, в \Java~\cite{Manson-al:POPL05}). 

Для ослабленных обращений, аннотированных режимом $\rlx$, 
как правило, гарантируется только выполнение свойства 
\emph{когерентности}~\cite{Alglave-al:TOPLAS14}.
Это свойство обеспечивает \emph{последовательную согласованность 
по каждой отдельной локации в памяти}.
В частности, из этого следует, что программа, 
состоящая из ослабленных обращений только к одной переменной, 
допускает только последовательно согласованные сценарии исполнения.

Обращения, аннотированные режимами захвата $\acq$ и освобождения $\rel$,
используются для поддержки идиомы передачи сообщений~\cite{Lahav-al:POPL16}.
Поток, выполняющий отправку сообщения, должен аннотировать соответствующую 
операцию записи в разделяемую память режимом доступа $\rel$, 
а поток, ожидающий это сообщение, должен аннотировать 
операцию чтения режимом доступа $\acq$.

Наконец, последовательно согласованные обращения, 
то есть аннотированные режимом $\sco$, 
при правильном использовании гарантируют 
семантику последовательной согласованности%
~\cite{Boehm-Adve:PLDI08, Lahav-al:PLDI17}.

\subsection{Требования к моделям памяти}
\label{sec:models-requirements}

Как уже упоминалось ранее на примере алгоритма Деккера, 
при разработке многопоточных программ необходимо 
учитывать модель памяти, предоставляемую языком программирования.
К моделям памяти предъявляются противоречивые требования. 
С одной стороны, более строгая модель допускает меньше сценариев поведения 
и предоставляет больше гарантий разработчику.
С другой стороны, более слабая модель позволяет 
выполнять большее количество различных оптимизаций, 
что приводит к повышению производительности программы. 
Таким образом, в дизайне модели памяти необходимо 
найти разумный компромисс между этими конфликтующими запросами.

В этом разделе будут более подробно описан 
набор типичных требований и критериев, предъявляемых 
к моделям памяти языков программирования. 

\subsubsection*{Оптимальность и корректность схемы компиляции}

\emph{Схемой компиляции} называется отображение
примитивов языка программирования в инструкции 
языка ассемблера конкретного семейства процессоров.
Будем подразумевать, что и выкоуровневый язык программирования и 
язык ассеблера в данном случае предоставляют одинаковый 
набор программных примитивов, описанных в разделе \ref{sec:models-primitives}.

\emph{Оптимальная} схема компиляции позволяет 
компилировать инструкций обращения к разделяемой памяти 
из языка программирования в инструкции целевого процессора
без необходимости вставки барьеров памяти и 
без усиления режима доступа обращений. 
Другими словами, наличие у языка программирование оптимальной схемы компиляции
позволяет компилировать программы на этом языке 
в эффективный код для целевого процессора.  
Напротив, использование неоптимальных схем компиляции
может приводить к снижению производительности кода
из-за наличия многочисленных барьеров памяти.
Но в то же время вставка дополнительных барьеров памяти
может предотвратить появление слабых сценариев поведения, 
допустимых спецификацией архитектуры процессора. 

\emph{Корректность} схемы компиляции гарантирует,
что множество сценариев поведения, допустимых моделью памяти процессора 
для скомпилированной версии программы,  
является подмножеством сценариев поведения исходной программы, 
допустимой моделью памяти языка программирования. 

Чтобы пояснить введеные выше понятия оптимальности 
и корректности схемы компиляции, рассмотрим пример. 
Программа \ref{ex:sb}, показанная ниже, является 
еще более упрощенным фрагментом алгоритма Деккера. 

\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
\tag{SB}\label{ex:sb}
\end{equation*}

Допустим, что язык программирования должен предоставлять
последовательно согласованную модель памяти и должен
поддерживать компиляцию в ассемблерный код процессоров семейства \IntelX.

Рассмотрим схему компиляции, которая 
компилирует инструкции чтения и записи 
разделяемых переменных в инструкцию \texttt{MOV}%
\footnote{В архитектуре \IntelX инструкция \texttt{MOV} 
используется для обычного чтения и записи в память.}. 
Такая схема компиляции является оптимальной, 
так как она не вставляет никакие дополнительные барьры памяти
и не усиливает режимы доступа обращений. 
Однако данная схема не является корректной, так как,
спецификации модели памяти~\IntelX, в частности, 
допускает для программы \ref{ex:sb} сценарий исполнения 
с результатом ${[r_1=0, r_2=0]}$, который 
не является последовательно согласованным.
Данный результат может появиться вследствие 
\emph{буферизации операций записи} --- 
операция записи ${\writeInst{}{x}{1}}$ может быть буферизована
и исполнена процессором после выполнения всех остальных инструкций программы.

С другой стороны, рассмотрим схему компиляции, 
которая вставляет инструкцию \texttt{mfence}
%% \footnote{В архитектуре \IntelX инструкция \texttt{mfence} 
%% является барьером памяти.}. 
после каждой операции записи%
~\cite{Sewell-al:CACM10, Batty-al:POPL11}.
Инструкция \texttt{mfence} является специальным барьером памяти 
в системе команд процессоров \IntelX. 
Выполнение данной инструкции приводит к сбросу буфера записей в основную память. 
Для программы \ref{ex:sb}, скомпилированной описанным выше способом,
результат ${[r_1=0, r_2=0]}$ уже является запрещенным 
моделью памяти процессоров \IntelX. 
Таким образом, альтернативная схема компиляции 
является корректной, но не оптимальной%
\footnote{На практике использование данной схемы 
компиляции может приводить к замедлению 
на 10-30\%~\cite{Marino-al:PLDI11, Liu-al:OOPSLA17}.}. 

К сожалению, модель последовательной согласованности 
не обладает оптимальной и корректной схемой компиляции 
для современных мультипроцессоров семейств 
\IntelX, \ARM и \POWER.
Это является одной из причин ослабления моделей памяти 
высокопроизводительных языков программирования. 

\subsubsection*{Корректность трансформаций кода}

Другим немаловажным требованием, предъявляемым к моделям памяти, 
является корректность трансформаций исходного кода, 
то есть правил переписывания исходного кода, 
применяемых при оптимизации программы компилятором.

\emph{Корректность} трансформации гарантирует,
что множество сценариев поведения программы, 
полученной после применения трансформации, 
является подмножеством допустимых сценариев 
поведения оригинальной программы.

Возвращаясь к программе \ref{ex:sb},
вновь рассмотрим модель последовательной согласованности 
и трансформацию \emph{перестановки независимых инструкций}.
Допустим что данная трансформация применяется к левому потоку 
и переставляет местами операции записи и чтения,
как показано ниже. 

\bigskip

\begin{minipage}{0.42\linewidth}
\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SB}\label{ex:sb-src}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.42\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{y}  \\
   \writeInst{}{x}{1}   \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SBtr}\label{ex:sb-tgt}
\end{equation*}
\end{minipage}

\bigskip

Для исходной версии программы (слева), 
результат $[r_1=0, r_2=0]$ \textbf{не является} 
последовательно согласованным, но для трансформированной 
версии программы этот результат уже \textbf{является} 
последовательно согласованным. 
Из чего можно сделать вывод, что перестановка независимых инструкций 
не является корректной трансформацией с точки зрения 
модели последовательной согласованности. 

В теории моделей памяти рассматривается вопрос корректности 
широкого набора базовых трансформаций.
Подробный список этих трансформаций с пояснениями 
может быть найден в работе~\cite{Moiseenko-al:PCS21}.
В данной работе будут обсуждаться только некоторые 
конкретные трансформации, которые будут вводиться по мере необходимости. 

Далее от требований о поддержке эффективной компиляции
и возможности проводить различные оптимизации, 
которые влекут к ослаблению модели памяти,
перейдем к требованиям о предоставляемых гарантиях, 
которые наоборот влекут к необходимости усиления модели памяти.

\subsubsection*{Гарантии для программ свободных от гонок}

Наиболее базовая гарантия, ожидаемая от модели памяти, 
требует, чтобы для программ, не содержащих \emph{гонок по данным}%
\footnote{Напомним, что гонкой по данным называется пара конкурентных 
обращений к одной и той же разделяемой переменной 
и как минимум одно из этих обращений является операцией записи.} 
допускались только последовательно согласованные сценарии исполнения. 
Это свойство также называется \emph{свободой от гонок}
(\emph{data-race freedom}, \DRF)~\cite{Manson-al:POPL05}.

В чуть более формальной формулировке, утвержается, 
что слабая модель памяти $M$ удовлетворяет свойству \DRF
если для любой программы $P$, которая не содержит 
гонок ни в одном последовательно согласованном сценарии исполнения,
модель $M$ допускает только последовательно согласованном сценарии%
\footnote{Свойство свободы от гонок в приведенной выше формулировке
также называется \DRFM{SC} по названию модели памяти 
sequential consistency. 
Можно также рассматривать свойство \DRF от другой 
произвольной модели $\mathsf{M}$, в этом случае это 
свойство называется \DRFM{M}.}.

Таким образом, свойство \DRF позволяет свести рассуждения о поведении 
многопоточной программы в слабой модели к рассуждениям о поведении 
этой же программы в более простой модели последовательной согласованности.
Для этого достаточно показать, что программа не имеет гонок в модели \SC. 

\subsubsection*{Спекулятивное исполнение}

Модели памяти также можно разделить по тому, 
требуют ли они спекулятивного исполнения инструкций или нет.
Рассмотрим еще один пример. 

\bigskip

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}     \\
  \writeInst{}{y}{1}      \\
}{
  \readInst{}{r_2}{y}     \\
  \writeInst{}{x}{r_2}    \\
}
\tag{LB}\label{ex:lb-spec}
\end{equation*}

\bigskip

Некоторые модели памяти, в частности, 
модели семейств мультипроцессоров \ARM и \POWER,
допускают для данной программы сценарий поведения, 
ведущий к результату ${[r_1=1, r_2=1]}$. 
Однако данный результат не может быть получен 
путем исполнения инструкции согласно их 
порядку внутри потоков (\emph{in-order execution}).
Для того чтобы получить этот результат, необходимо 
использовать \emph{спекулятивное исполнение}
(\emph{speculative execution})~\cite{Boudol-Petri:ESOP10,Boehm-Demsky:MSPC14}.
Например, данный результат можно получить, если 
буферизировать операцию чтения $\readInst{}{r_1}{x}$ в левом потоке
и исполнить инструкцию записи $\writeInst{}{y}{1}$ вне очереди%
\footnote{Из этого происходит название приведенной программы --- 
буферизация операции чтения (\emph{load buffering}, \ref{ex:lb-spec})}.

Важно отметить, что неограниченное использование 
спекулятивного исполнения может привести к нежелательным последствиям. 
Чтобы продемонстрировать проблему, рассмотрим следующий вариант 
программы с буферизацией операции чтения.

\bigskip

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}   \\
  \writeInst{}{y}{r_1}  \\
}{
  \readInst{}{r_2}{y}   \\
  \writeInst{}{x}{r_2}  \\
}
\tag{LB+dep}\label{ex:lb+dep-spec}
\end{equation*}

\bigskip

Сценарий исполнения, в котором сначала происходит 
спекулятивное исполнение операции записи 
в переменную \tcode{y} значения \tcode{1} в левом потоке, 
затем чтение этого значения и его запись в переменную \tcode{x}
в правом потоке, а затем вновь чтение его обратно в левом потоке, 
ведет к циклу причинно-следственных связей 
и неожиданному результату ${[r_1=1, r_2=1]}$.
Прочитанные значения \tcode{1} в примере выше 
также называются \emph{значениями из воздуха} 
(\emph{out of thin-air})~\cite{Batty-al:ESOP15}.
Для того чтобы запретить появление подобных значений 
из воздуха модель памяти должна ограничивать использование
спекулятивного исполнения. 
Более подробно возможные решения этой проблемы 
обсуждаются в разделах \ref{sec:models-classes}, 
\ref{sec:exec-graphs} и \ref{sec:wkmo-eventstruct}.

%% Чтобы представить последние два свойства, 
%% а именно, наличие спекулятивного исполнения и значений из воздуха, 
%% мы рассмотрим ещё один пример:

%% \emph{Корректная} трансформация должна сохранять семантику программы. 
%% В нашем контексте, как и в случае корректности схемы компиляции,
%% это означает, что множество допустимых сценариев поведения 
%% программы после применения трансформации должно 
%% быть подмножеством допустимых сценариев поведения оригинальной программы.


%% Основные требования предъявлемые к моделям памяти,
%% их краткое описание и мотивация их введения:

%% \begin{itemize}
%%   \item Корректность компиляции.
%%   \item Корректность трансформаций программ.
%%   \item Предоставляемые гарантии для рассуждения о поведении программ.
%%     Здесь также будет сделан акцент на инструментах
%%     для верификации многопоточных программ. 
%% \end{itemize}

\subsection{Классы моделей памяти}
\label{sec:models-classes}

Рассмотрим программы \ref{ex:LB-nodep}, \ref{ex:LB-fakedep} и \ref{ex:LB-dep}, 
показанные ниже. \TODO{}

\input{Dissertation/fig/lb-ex}

Основные классы моделей памяти (по материалам обзорной статьи~\cite{Moiseenko-al:PCS21}).
Описание свойств этих классов и компромиссов в их дизайне
в соответствии с требованиями, предъявленными в предыдущем разделе. 

\subsection{Сравнение моделей памяти и открытые проблемы}
\label{sec:models-summary}

Подведение итога обзора моделей памяти.
Фрагмент сравнительной таблицы из обзорной статьи~\cite{Moiseenko-al:PCS21}.
Обозначение research gaps, которые закрывает данная диссертация, а именно:

\begin{itemize}
  \item классическая теория структур событий для моделей памяти
    сохраняющих программный порядок;
  \item корректность компиляции для модели \Wkm;
  \item автоматическая верификация многопоточных программ
    (model checking) в модели \WkmS.
\end{itemize}

\section{Формальная семантика параллельных программ и моделей памяти}

В этом разделе приводятся определения различных формализмов,
используемых для задания семантики многопоточных программ и моделей памяти.
В разделе \cref{sec:lts} дано определение \emph{систем помеченных переходов}
и \emph{операционных семантик с чередованием} 
(\emph{interleaving operational semanitcs}).
В разделе \cref{sec:pomsets-eventstruct} приводится альтернативный способ
задания семантики многопоточных программ без чередования 
(\emph{non-interleaving}) 
с помощью семантических доменов \emph{истинной конкурентности} 
(\emph{true concurrency}), а именно 
\emph{языков частично упорядоченных мультимножеств} и \emph{структур событий}.
В разделе \cref{sec:exec-graphs} вводится понятие графов сценариев исполнения
и аксиоматических моделей памяти, а также приводится краткое сравнение
графов сценариев исполнения и частично упорядоченных мультимножеств.
Наконец, в разделе \cref{sec:wkmo-eventstruct} вводится
специальный тип структур событий, используемых в модели \Wkm.

\subsection{Системы помеченных переходов}
\label{sec:lts}

Системы помеченных переходов являются традиционным 
способом задания операционной семантики. 
Системы помеченных переходов это (потенциально бесконечный) граф, 
вершины в котором представляют внутрение состояния системы, а
ребра соответствуют выполнению шага вычислений. 
Метка ребра задает видимый эффект выполения данного шага вычислений.
%% Множество трасс автомата задает его ``последовательную'' спецификацию, 
%% а список меток, индуцируемый трассой, определяет
%% наблюдаемое поведение автомата. 

\begin{definition}
  \label{def:lts}
  \emph{Система помеченных переходов} --- это тройка
    $\LTS \defeq \tup{\State, \Label, \TrRel}$, где 
  \begin{itemize}
    \item $\State$ --- множество состояний;
    \item $\Label$ --- множество меток, также называемое \emph{алфавитом};
    \item $R \subseteq L \times S \times S$ --- помеченное отношение перехода.
  \end{itemize}
  Для обозначения наличия перехода между состояниями используется следующая нотация:
    \[
    \begin{array}{lcr@{\hspace{3em}}lcr}
    \ltr[R]{\ell}{s}{s'} & \defeq & \step{\ell}{s}{s'} \in \TrRel                     &
    \tr[R]{s}{s'}        & \defeq & \exists \ell \ldotp \step{\ell}{s}{s'} \in \TrRel \\
    \end{array}
    \]
  \emph{Трассой} помеченной системой переходов называется чередующаяся последовательность  
  состояний $s_0, s_1, \ldots, s_n \in \Label$ 
  и меток $\ell_1, \ldots, \ell_n \in L$, 
  такая что выполняется условие
  $$s_0 \xrightarrow{\ell_1} s_1 \xrightarrow{\ell_2} s_2 \xrightarrow{\ell_3} \ldots \xrightarrow{\ell_n} s_n$$
  Язык, принимаемый системой переходов в начальном состоянии $s_0$ 
  это множество последовательностей слов над алфавитом $\Label$, 
  таких что для каждого слова существует соответствующая 
  трасса, начинающася в $s_0$:
  $$ \langof{\LTS, s_0} \defeq \set{ 
       \ell_1 \ldots \ell_n ~|~ \exists s_1, \ldots, s_n \ldotp 
       s_0 \xrightarrow{\ell_1} s_1 \xrightarrow{\ell_2} \ldots \xrightarrow{\ell_n} s_n
     } 
  $$
  
\end{definition}

\input{Dissertation/fig/lts-lang-ex}

На \cref{fig:lts-ex} показан пример системы помеченных переходов, 
а на \cref{fig:lang-ex} пример языка, 
принимаемаемого этой системой в состоянии $s_0$.

В рамках так называемой операционной семантики с чередованием
(interleaving semantics) поведение многопоточной программы
определяется как поочередное исполнение атомарных действий параллельных потоков.

\begin{definition}
  \label{def:lts-par}
  Параллельной композицией двух систем переходов $\LTS_1$ и $\LTS_2$
  будем называть систему переходов
  $\parlts{\LTS_1}{\LTS_2} \defeq \tup{\State_1 \times \State_2, \Label, \TrRel_{\parSymb}}$
  где $\TrRel_{\parSymb}$ определяется следующим образом:
  \begin{itemize}
    \item $\ltr[\TrRel_1]{\ell}{s_1}{s'_1}$ влечет
          $\ltr[\TrRel_{\parSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s'_1, s_2}}$, и
    \item $\ltr[\TrRel_2]{\ell}{s_2}{s'_2}$ влечет
          $\ltr[\TrRel_{\parSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s_1, s'_2}}$.
  \end{itemize}
\end{definition}

Если при этом потоки имеют доступ к общему ресурсу 
(например, разделяемой памяти), то в таком случае можно
семантику ресурса также задать с помощью системы переходов
а затем рассмотреть произведение параллельной композиции потоков и ресурса.  

\begin{definition}
  \label{def:lts-par}
  Произведением двух систем переходов $\LTS_1$ и $\LTS_2$
  будем называть систему переходов
  $\prodlts{\LTS_1}{\LTS_2} \defeq \tup{\State_1 \times \State_2, \Label, \TrRel_{\prodSymb}}$
  где $\TrRel_{\prodSymb}$ определяется следующим образом:
  \begin{itemize}
    \item $\ltr[\TrRel_{\prodSymb}]{\ell}{\tup{s_1, s_2}}{\tup{s'_1, s'_2}}$ 
      тогда и только тогда, когда 
      $\ltr[\TrRel_1]{\ell}{s_1}{s'_1}$ и $\ltr[\TrRel_2]{\ell}{s_2}{s'_2}$.
  \end{itemize}
\end{definition}

Таким образом, если система помеченных переходов $\LTS_{\thrdSymb}$ 
задает семантику потоков, а система $\LTS_{\resSymb}$ --- 
семантику разделяемого ресурса, тогда 
$(\LTS_{\thrdSymb} \parSymb \dots \parSymb \LTS_{\thrdSymb}) \prodSymb \LTS_{\resSymb}$
задает семантику всей системы, состоящей из $n$ потоков и разделяемого ресурса.

\subsection{Языки помсетов и простые структуры событий}
\label{sec:pomsets-eventstruct}

Операционные семантики с чередованием представляют 
простой и интуитивно понятный подход для моделирования
многопоточных программ. Однако его недостаток заключается в том, 
что с ростом программы экспоненциально растет количество трасс, 
допустимых операционной семантикой. 

В попытке преодолеть эту проблему, исследователями 
были предложены различные альтернативные 
подходы к заданию семантики многопоточных программ, 
которые позволяют более компактно представить пространство 
возможных сценариев поведения таких программ. 
Данный класс семантик принято называть 
\emph{семантиками без чередования} (\emph{non-interleaving semantics})
или также \emph{истинно конкурентными семантиками}
(\emph{true concurrent semantics})~\cite{Nielsen:REX93}.
Из данного класса семантик в рамках 
данной диссертации интерес представляют 
\emph{языки частично упорядоченных мультимножеств}
(кратко --- языки помсетов)~\cite{Pratt:CONCUR84,Gischer:TCS88}, 
и \emph{структуры событий}~\cite{Winskel:86}.

Языки помеченных частично упорядоченных множеств является
обощением понятия обычных ``последовательных'' языков, 
то есть множества слов данного алфавита. 
Обобщение заключается в переходе от линейного порядка 
на символах алфавита в рамках слова к частичному порядку.
Частично упорядоченное множество соответствует одному
сценарию исполнения многопоточной программы.
Элементы этого множества представляют
атомарные шаги вычисления и называются \emph{событиями}.
Каждому событию ставится в соответствие семантическая \emph{метка} ---
символ заданного алфавита.
Если событие $e_1$ упорядочено перед ~$e_2$, $e_1 \ca e_2$, 
тогда считается что событие~$e_2$ в
сценарии исполнения программы зависит от события~$e_1$.
Если не выполняется ни $e_1 \ca e_2$ ни $e_2 \ca e_1$ 
тогда события $e_1$ и $e_2$ считаются параллельными, 
$e_1 \co e_2$. 

\begin{definition}
  \label{def:lposet}
  \emph{Помеченное частично упорядоченное множество} над множеством меток $\Label$, 
  это тройка $\tup{\Event, \lab, \ca}$, где 
  \begin{itemize}
    \item $\Event$ это множество \emph{событий};
    \item $\lab : \Event \fun \Label$ \emph{функция разметки событий};
    \item $\ca \subseteq \Event \times \Event$ это частичный порядок 
      \emph{причинно-следственной связи} между событиями. 
  \end{itemize}
  Множество всех помеченных частично упорядоченных множеств над алфавитом $\Label$
  будем обозначать как $\lPoset[\Label]$. 
\end{definition}

Отметим, что при работе c помеченными частично упорядоченными множествами
конкретные идентификаторы событий как правило неважны,
важна лишь их разметка и отношение причинно-следственной связи между ними.
Таким образом, с помеченными частично упорядоченными множествами 
работают по модулю переименования событий, то есть с точностью до изоморфизма.

\begin{definition}
  \label{def:lposet-morph}
  Рассмотрим $p, q \in \lPoset[\Label]$. Функция $f : E_p \fun E_q$ называется:
  \begin{itemize}
    \item \emph{сохраняющей метки} если ${\lab_q(f(e)) = \lab_p(e)}$;
    \item \emph{сохраняющей порядок} если ${e_1 \ca_p e_2}$ влечет ${f(e_1) \ca_q f(e_2)}$;
    \item \emph{вкладывающей порядок} если ${e_1 \ca_p e_2}$ тогда и только тогда, когда ${f(e_1) \ca_q f(e_2)}$.
  \end{itemize}
  \emph{Гомоморфизмом} частично упорядоченных помеченных множеств называется
  функция, сохраняющая метки и порядок. Если более того эта фунцкия
  биективна и вкладываюет порядок, то она называется изоморфизмом.
  Запись $p \iso q$ означает что $p$ и $q$ изоморфны,
  то есть существует изоморфная функция между носителями $p$ и $q$.
\end{definition}

\begin{definition}
  \label{def:pomset}
  Помеченные частично упорядоченные мультимножества, 
  или, кратко, \emph{помсеты} (от англ. \emph{partially ordered multiset, pomset}), 
  это классы помеченных частично упорядоченных множеств по модулю изоморфизма: 
  $${\Pom[\Label] \defeq \lPoset[\Label] / {\iso}}.$$ 
  Язык помсетов --- это множество помсетов: 
  $${\Pomlang[\Label] \defeq \pwset{\Pom[\Label]}}.$$ 
\end{definition}

\input{Dissertation/fig/pom-es-ex}

На \cref{fig:pom-ex} можно видеть пример языка помсетов. 
Этот язык помсетов кодирует обычный язык, показанный \cref{fig:lang-ex}, 
так как каждое слово из обычного языка является дополнением некоторого 
частичного упорядоченного множества из языка помcетов
до линейно упорядоченного множества. 
Формально, связь языка помсетов и обычного языка можно установить 
с помощью понятия \emph{линеаризации помсета}.

\begin{definition}
  \label{def:pomset-subs}
  Помсет $p$ \emph{поглощается} $q$, $p \subs q$, 
  если существует биективный гомоморфизм из $q$ в $p$.
  В таком случае также говорят, что $p$ более упорядочено чем $q$.
\end{definition}

\begin{definition}
  \label{def:pomset-lin}
  Помсет $p$ является линеаризацией $q$, 
  что обозначается как $p \in \Lin{q}$,
  если $p$ является линейно упорядоченным и 
  поглощается $q$, $p \subs q$.
  Линеаризация языка помсетов $P$ определяется 
  как объединение линеаризации всех входящих в язык помсетов:
  $$ \Lin{P} \defeq \bigcup_{p \in P}\Lin{p} $$
  Наконец, можно сказать что язык помсетов $P \in \Pomlang[\Label]$
  соответствует обычному языку $L \in \Lang{\Label}$, если $\Lin{P} = L$.
\end{definition}

Множество помсетов можно объединить в одну \emph{структуру событий},
и таким образом представить язык помсетов как одно частично упорядоченное множество.
Существует множество видов структур событий~\cite{}, 
в контексте данной работы будем рассматривать класс \emph{простых структур событий}.
Везде далее под термином \emph{структура событий} будем подразумевать 
именно простую структуру событий, если иное не сказано явно. 

По сравнению с помеченным частично упорядоченным множеством, 
простые структуры событий позволяют дополнительно выразить тот факт, 
что два события $e_1$ и $e_2$ находятся в конфликте.
Это означает, что эти два события не могут одновременно 
принадлежать одному сценарию исполнения программы. 

\begin{definition}
  \label{def:lposet-dwfin}
  Будем говорить, что помеченное частично упорядоченное множество 
  $p = \tup{\Event, \lab, \ca}$ является \emph{префикс конечным} 
  если каждое событие имеет конечное число предшественников, 
  то есть для любого $e \in \Event$ множество 
  $\dwset{e} \defeq \set{e' ~|~ e' \ca e}$ конечно.
\end{definition}

\begin{definition}
  \label{def:prime-es}
  \emph{Простая структура событий с бинарным конфликтом} над множеством меток $\Label$ 
  это кортеж $\tup{\Event, \lab, \ca, \cf}$, где 
  $\tup{\Event, \lab, \ca}$ это префикс-конечное помеченное 
  частично упорядоченное множество, 
  а $\cf \suq \Event \times \Event$ --- это \emph{бинарное отношение конфликта}, 
  которое является иррефлексивным, симметричным и 
  удовлетворяет свойству \emph{наследственности}:
  $$ e_1 \cf e_2 ~\text{и}~ e_2 \ca e_3 ~\text{влечет}~ e_1 \cf e_3.$$
\end{definition}

Отметим, что зачастую язык помсетов может иметь более сложную структуру 
конфликтности между событиями, которая не может быть сведена 
к бинарному конфликту между парой событий. 
В таком случае рассматривают простые структуры событий более общего вида. 

\begin{definition}
  \label{def:prime-cons-es}
  \emph{Простая структура событий с предикатом консистентости} над множеством меток $\Label$ 
  это кортеж $\tup{\Event, \lab, \ca, \Cons}$, где 
  $\tup{\Event, \lab, \ca}$ это префикс-конечное помеченное 
  частично упорядоченное множество, 
  а $\Cons \suq \pwfset{\Event}$ --- это \emph{предикат консистентности}, 
  который должен удовлетворять следующим условиям:
  \begin{enumerate}
    \item \label{ax:prime-cons-emp}
      $\emptyset \in \Cons$,
    \item \label{ax:prime-cons-subs}
      $X \subseteq Y$ и $Y \in \Cons$ влечет $X \in \Cons$,
    \item \label{ax:prime-cons-ca}
      $e_1 \ca e_2$ и $\set{e_2} \cup X \in \Cons$ 
      влечет $\set{e_1} \cup X \in \Cons$.
  \end{enumerate}
\end{definition}

Можно видеть, что простые структуры событий с бинарным конфликтом
являются частным случаем простых структур событий 
с предикатом консистентности. 
Действительно, для простой структуры событий с бинарным конфликтом
можно определить предикат консистентности следующим образом:
$$X \in \Cons \iff \forall e_1~e_2 \in X \ldotp \neg e_1 \cf e_2.$$

Наконец, формально определим язык помсетов, порождаемый структурой событий. 

\begin{definition}
  \label{def:es-cfg}
  Пусть $S = \tup{\Event, \lab, \ca, \Cons}$ простая структура событий 
  с предикатом консистентности. Тогда подмножество событий 
  $X \suq \Event$ называется \emph{конфигурацией} структуры $S$ 
  если оно является префикс-замкнутым, а все его конечные подмножества 
  являются консистентными, то есть 
  \begin{itemize}
    \item $\dwset{X} \defeq {e' ~|~ \exists e \in X \ldotp~ e' \ca e } \suq X$, 
    \item $Y \finsubseteq X$ implies $Y \in \Cons$.
  \end{itemize}
  Будем обозначать как $\Cfg{S}$ множество всех конфигураций $S$.
\end{definition}

\begin{definition}
  \label{def:es-pomlang}
  Язык помсетов, порождаемый структурой событий $S = \tup{\Event, \lab, \ca, \Cons}$, 
  определяется следующим образом:
  $$ \pomlang{S} \defeq \set{p ~|~ \exists X \in \Cfg{S} \ldotp p = S\rst{X} }$$
  где $S\rst{X} \defeq {X, \lab\rst{X}, \ca\rst{X}}$ это сужение 
  структуры событий $S$ на консистентное подмножество событий $X$.
\end{definition}

\subsection{Графы сценариев исполнения}
\label{sec:exec-graphs}

Далее перейдем к описанию формализмов, используемых для
формального определения моделей памяти.

Напомним, что под моделью памяти понимается
семантика многопоточной системы, оперирующей с разделяемой памятью.
Поэтому, как уже упоминалось в \cref{sec:lts},
модель памяти можно определить в терминах операционной семантики.
В таком случае система переходов
$(\LTS_{\thrdSymb} \parSymb \dots \parSymb \LTS_{\thrdSymb}) \prodSymb \LTS_{\memSymb}$
будет описывать многопоточную систему, состояющую из $n$ потоков
и разделямой памяти, где $\LTS_{\thrdSymb}$ --- это система переходов,
описывающая поведение потоков, а $\LTS_{\memSymb}$ --- система переходов,
описывающая поведение разделяемой памяти. 

Как уже отмечалось, в контексте моделирования
многопоточных систем одним из недостатков подхода,
основанного на операционной семантике, 
является экспоненциально рост количество трасс системы.
В контексте слабых моделей памяти у данного подхода
также есть и другой недостаток.
Проблема заключается в том, что для кодирования каждой
отдельной модели памяти необходимо разработать
собственное представление этой модели памяти 
в терминах системы переходов $\LTS_{\memSymb}$.
При этом такая система может быть устроено
достаточно сложным образом и требовать моделирования
множества различных структур данных, например,
буферов операций, очередей сообщений,
многоуровневых кэшей и так далее.  

Поэтому для спецификации моделей памяти
зачастую используют альтернативный \emph{аксиоматический стиль}.
В аксиоматическом стиле задано большинство моделей
современных мультипроцессоров, например,
\Intel~\cite{Sewell-al:CACM10}, 
\POWER~\cite{Sarkar-al:PLDI11,Alglave-al:TOPLAS14}),
\ARM~\cite{Pulte-al:POPL18,Alglave-al:TOPLAS14}),
и некоторых языков программирования,
например, \OCaml~\cite{Dolan-al:PLDI18}, \JS~\cite{Watt-al:PLDI2020}.

Модель памяти в аксиоматическом стиле
определяется как множество консистентных 
\emph{графов сценариев исполнения} (\emph{execution graphs}).
В этом графе вершинами являются атомарные события,
а ребра формируют различные отношения между этими событиями.
Графы сценариев исполнения похожи на помсеты,
главное отличие между ними заключается в том, что 
помсет состоит из единственного
отношения причинно-следственной связи, 
а граф сценариев исполнения состоит из
нескольких отношений, наделенных различной семантикой.
Например, отношение \emph{программного порядка} (\emph{program order}) $\lPO$ 
задает порядок, в котором выполняются события в каждом потоке,
а отношение \emph{читает-из} (\emph{reads-from}) $\lRF$, 
для каждого события записи указывает 
какие события чтения выполняют операцию чтения из него. 
На Рис.\cref{fig:LB-nodep-execs} показаны примеры графов сценариев исполнения 
соответствующих программе \ref{ex:LB-nodep}.

\input{Dissertation/fig/execs-ex}

Далее введем формальное определение графов сценариев исполнения.
Но сначала необходимо также ввести тип семантических меток (алфавита)
для описания абстракции разделяемой памяти.

\begin{definition}
  \label{def:mem-aux}
  Введем следующие множества:
  \begin{itemize}
    \item $\Tid \suq \N$ обозначает множество \emph{идентификаторов потоков}, 
      а поток с идентификатором $t_0 \defeq 0$
      обозначает выделенный \emph{инициализирующий} поток;
    \item $\Loc$ обозначает множество \emph{разделяемых переменных} 
      (или \emph{локаций});
    \item $\Mod \defeq \set{\na, \rlx, \acq, \rel, \acqrel, \sco}$
      обозначает множество \emph{режимов доступа} (\emph{access modes})
      к разделяемым переменным;
    \item $\Val$ обозначает множество возможных \emph{значений}. 
  \end{itemize}  
\end{definition}

\begin{definition}
  \label{def:mem-lab}
  Определим множество меток $\MemLab$, 
  соответствующих абстракции разделяемой памяти. 
  Метка $l \in \MemLab$ принимает одну из следующих форм:
  \begin{itemize}
    \item $\rlab{o}{x}{v}$ --- метка операции чтения значения $v$ из переменной $x$, 
      аннотированная режимом доступа $o$;
    \item $\wlab{o}{x}{v}$ --- метка операции записи значения $v$ в переменную $x$, 
      аннотированная режимом доступа $o$;
    \item $\lF^o$ --- метка операции барьера, аннотированная режимом $o$.
  \end{itemize}
  Если у метки опущен режим доступа, то будем считать что 
  она аннотирована режимом $\rlx$.
\end{definition}

\begin{definition}
  \label{def:exec-graph}
  \emph{Граф сценария исполнения} (\emph{execution graph}) $G$ 
  это кортеж $\tup{\lE, \lLAB, \lPO, \lRMW, \lRF, \lCO}$.
  Компоненты этого кортежа определены следующим образом.
  \begin{itemize}

    \item $\lE \suq \N$ --- это множество событий.

    \item $\lTID : \lE \fun \Tid$ --- это функция, 
      которая присваивает каждому событию идентификатор потока.
      Множество событий, принадлежащих инициализирующему потоку,
      определяется как ${\lEi \defeq \set{e \in \lE \sth \lTID(e) = t_0}}$.

    \item $\lLAB : \lE \fun \MemLab$ --- это функция, 
      которая назначает каждому событию метку. 
      Данная функция также индуцирует частично определенные функции
      $\lTYP$, $\lLOC$, $\lMOD$, $\lVAL$, которые возвращают
      тип, локацию, режим доступа и значение метки соответственно. 
      Также положим, что $\lR$, $\lW$ и $\lF$ обозначают подмножества 
      событий с меткой операции чтения, записи и барьера соответственно.

    \item $\lPO \suq \lE \times \lE$ --- это отношение 
      \emph{программного порядка} (\emph{program order}).
      Это отношение строгого частичного порядка на событиях, 
      которое полностью упорядочивает все события внутри одного потока
      согласно потоку управления программы. 
      Дополнительно полагается, что инициализирующие события $\lEi$ 
      упорядочены программным порядоком раньше всех других событий.
      Также введем отношение \emph{непосредственного программного порядка}
      (\emph{immediate program order}): 
      будем считать событие $e_1$ непосредственным $\lPO$-предшественником 
      события $e_2$ если $e_1$ предшествует $e_2$ 
      и между ними нет других событий.
      \begin{equation*}
        \lPOimm \defeq \lPO \setminus (\lPO \seqc \lPO)
      \end{equation*}

    \item $\lRMW \suq \lRex \seqc \lPOimm \cap \lEQLOC \seqc \lWex$ ---
      отношение соединяющие \emph{атомарные пары событий чтения-записи}. 
      Если $\tup{r, w} \in \lRMW$ тогда считается, что данная пара событий
      возникла в ходе исполнения одной инструкции атомарного чтения-записи, 
      например, инструкции \emph{атомарного инкремента} (\emph{fetch-and-add}, \FADD), 
      или инструкции \emph{атомарного сравнения с обменом} 
      (\emph{compare-and-swap}, \CAS).

    \item $\lRF \suq [\lW] \seqc \lEQLOC \cap \lEQVAL \seqc [\lR]$ --- отношение 
      \emph{читает-из} (\emph{reads-from}). 
      Это отношение связывает событие-запись с событиями-чтениями, 
      которые выполняют операцию чтения из него. 
      Для каждого события чтения должно существовать 
      событие записи, из которого выполняется чтение: 
      $$ r \in \lR \implies \exists w \in \lW \ldotp \tup{w, r} \in \lRF.$$
      Более того, каждое событие чтения может быть связано только с одним событием записи:
      $$ \tup{w_1,r} \in \lRF \wedge \tup{w_2,r} \in \lRF \implies w_1 = w_2.$$

      Дополнительно будем рассматривать внутреннею (\emph{internal}) 
      и внешнюю (\emph{external}) $\lRFE$ версию отношения ``читает-из''
      (обозначается как $\lRFI$ и $\lRFE$ соответcтвенно), 
      в зависимости от того принадлежит ли пара событий записи и чтения
      одному потоку или разным потокам.
      \[\def\arraystretch{1}
       \begin{array}{c@{\qquad}c@{\qquad}c@{\qquad}c}
         \lRFI \defeq \lRF \cap \lPO      &
         \lRFE \defeq \lRF \setminus \lPO
       \end{array}
      \]

    \item $\lCO \suq [\lW] \seqc \lEQLOC \seqc [\lW]$ --- это отношение 
      \emph{когерентности}. Это отношение строгого частичного порядка на событиях, 
      которое полностью упорядочивает все операции записи в одну локацию. 
      Это отношение представляет порядок, в котором операции записи 
      продвигаются в основную память и становятся видимы другим потокам. 
      \begin{equation*}
        \forall w_1, w_2 \in \lW \ldotp~ 
          \lLOC(w_1) = \lLOC(w_2) \implies \tup{w_1, w_2} \in \lCO \cup \lCO^{-1}
      \end{equation*}
      По аналогии с отношением ``читает-из'' также определим
      внутреннею и внешнюю версии отношения когерентности.
      \[\def\arraystretch{1}
       \begin{array}{c@{\qquad}c@{\qquad}c@{\qquad}c}
         \lCOI \defeq \lCO \cap \lPO      &
         \lCOE \defeq \lCO \setminus \lPO
       \end{array}
      \]

  \end{itemize}

  Множество всех графов сценариев исполнения будем обозначать как~$\ExecG$.
\end{definition}

\begin{definition}
  \label{def:ax-memory-model}
  \emph{Аксиоматическая модель памяти} (\emph{axiomatic memory model}) $M$ 
  задается как подмножество графов сценариев исполнения: $M \suq \ExecG$.
  Граф $G$ называется \emph{консистентым} с точки зрения модели $M$, 
  или просто $M$-\emph{консистентым}, если $G \in M$.
\end{definition}

Модели памяти, сохраняющие программный порядок, накладывают 
ограничение консистентности требующее, чтобы объединение 
отношений программного порядка и ``читает-из'' было ацикличным. 

\begin{definition}
Будем говорить, что граф сценария исполнения $G$ 
\emph{сохраняет программный порядок}, если выполняются следующее условие: 
\begin{itemize}
  \item $\lPO \cup \lRF$ является ацикличным отношением.
    \labelAxiom{$\lPORF$-acyclic}{ax:porf-acyc}
\end{itemize}
Обозначим множество всех таких графов как $\PorfExecG$.
Также будем говорить, что модель памяти $M$, 
заданная в аксиоматическом стиле, сохраняет программный порядок, 
если любой $M$-консистентный граф сохраняет программный порядок, 
то есть ${M \suq \PorfExecG}$.
\end{definition}

Например, среди графов, показанных на Рис.\cref{fig:LB-nodep-execs}, 
графы \circledb{A}, \circledb{B} и \circledb{C} сохраняют программный порядок, 
а граф \circledb{D} --- нет, так как он содержит $\lPO \cup \lRF$ цикл.
Таким образом, сценарий исполнения программы \ref{ex:LB-nodep},
соответствующий графу \circledb{D},
и в результате которого в локальные переменные $a$ и $b$ записано значение $1$,
запрещен моделями памяти, сохраняющими программный порядок.

Модели памяти, сохраняющие синтаксические зависимости, 
могут допускать некоторые $\lPO \cup \lRF$ цикличные графы. 
Данные модели гарантируют сохранение порядка между событиями
одного потока только если они связаны отношением 
\emph{сохраняемого программного порядка} (\emph{preserved program order}) $\lPPO$, 
которое является подмножеством отношения программного порядка $\lPO$. 
Отношение сохраняемого программного порядка
строится с помощью отношения \emph{синтаксических зависимостей} между событиями, 
данное отношение включает отношения зависимости по данным, по управлению, и другие. 

\begin{definition}
  \label{def:imm-exec-graph}
  \emph{Расширенным графом сценария исполнения} будем называть
  обычный граф сценария исполнения (\cref{def:exec-graph}), дополненный отношениями 
  \emph{зависимости по данным} (\emph{data dependency}) $\lDATA$, 
  \emph{зависимости по потоку управления} (\emph{control dependency}) $\lCTRL$, 
  \emph{зависимости по целевому адресу} (\emph{address dependency}) $\lADDR$, 
  и \emph{зависимость по операции \CAS} (\emph{\CAS dependency}) $\lRMWDEP$.
\end{definition}

\input{Dissertation/fig/lb-execs}

В контексте моделей памяти, сохраняющих синтаксические зависимости,
под графом сценария исполнения будем подразумевать расширенный граф, 
который дополнен отношениями зависимости. 

Точное определение сохраняемого программного порядка может 
варьироваться в зависимости от конкретной модели памяти, 
но как правило оно включает как минимум объединение 
отношений зависимости, представленных выше. 
Далее модели памяти, сохраняющие синтаксические зависимости, 
накладывают ограничение консистентности требующее, чтобы объединение 
отношений сохраняемого программного порядка и 
внешнего отношения ``читает-из'' было ацикличным. 

\begin{definition}
Будем говорить, что граф сценария исполнения $G$ 
\emph{сохраняет синтаксические зависимости}, если выполняются следующие условия: 
\begin{itemize}
  \item $\lDEPS \suq \lPPO$;
    \labelAxiom{$\lPPO$-deps}{ax:ppo-deps}
  \item $\lPPO \cup \lRFE$ является ацикличным отношением.
    \labelAxiom{$\lPPORF$-acyclic}{ax:pporf-acyc}
\end{itemize}
Обозначим множество всех таких графов как $\PporfExecG$.
Также будем говорить, что модель памяти $M$, 
заданная в аксиоматическом стиле, сохраняет программный порядок, 
если любой $M$-консистентный граф сохраняет программный порядок, 
то есть ${M \suq \PporfExecG}$.
\end{definition}

Рассмотрим, например, пару $\lPO \cup \lRF$ цикличных графов, 
изображенных на Рис.\cref{fig:LB-ppo-execs}.
Данные графы соответствуют сценарию исполнения 
с результатом $a = b = 1$. 
Отметим, что при этом граф, показанный на 
Рис.\cref{fig:LB-nodep-ppo-exec}, является $\lPPO \cup \lRFE$
ацикличным, а граф на Рис.\cref{fig:LB-dep-ppo-exec} содержит такой цикл. 
Это объясняется тем, что в программу \ref{ex:LB-nodep} инстукции 
в левом потоке не связаны зависистью по данным, 
а в программах \ref{ex:LB-fakedep}~и~\ref{ex:LB-dep}
инструкции в обоих потоках связаны зависистью по данным. 
Таким образом, модели памяти, сохраняющие синтаксические зависимости, 
допускают сценарию исполнения с результатом $a = b = 1$ 
для программы \ref{ex:LB-nodep}, 
но не для программ \ref{ex:LB-fakedep}~и~\ref{ex:LB-dep}. 

%% \begin{definition}
%%   \label{def:imm-deps-rel}
%%   Для расширенного графа сценария исполнения определим 
%%   объединенное отношение \emph{зависимости} (\emph{dependency}) 
%%   следующим образом:
%%   $$ \lDEPS \defeq \lDATA \cup \lCTRL \cup \lADDR \seq \lPO^? \cup \lRMWDEP. $$
%% \end{definition}

%% \begin{definition}
%%   \label{def:imm-deps-rel}
%%   Для расширенного графа сценария исполнения определим 
%%   объединенное отношение \emph{зависимости} (\emph{dependency}) 
%%   следующим образом:
%%   $$ \lDEPS \defeq \lDATA \cup \lCTRL \cup \lADDR \seq \lPO^? \cup \lRMWDEP. $$
%% \end{definition}

\subsection{Структуры событий в модели \Wkm}
\label{sec:wkmo-eventstruct}

Определение класса структур событий, использующихся в модели \Wkm.
