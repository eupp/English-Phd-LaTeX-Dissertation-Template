\chapter{Верификация методом проверки модели для \WkmS}
\label{ch:mc-weakestmo2}

В данной главе описывается разработанный в рамках данной диссертации 
алгоритм проверки моделей \wmc для верификации 
многопоточных программ в модели \WkmS.
Предложенный алгоритм был внедрен в систему \genmc --- 
инструмент для автоматической верификации многопоточных программ, 
написанных на языке \CLANG, в модели памяти \RCMM. 
Таким образом предложенный алгоритм \wmc расширяет 
оригинальный алгоритм \genmc, добавляя в него 
поддержку модели памяти \WkmS.  

Алгоритм \wmc полагается на новые свойства модели \WkmS, 
а именно свободу от буферизации операций чтения и 
локальность сертификации, чтобы реализовать ключевые 
оптимизации и сделать верификацию в модели \WkmS возможной на практике.  
В рамках серии экспериментов показывается, что 
новый алгоритм \wmc обладает лучшей производительностью 
по сравнению с аналогами.

Данная глава организована следующим образом. 
В разделе \ref{sec:mc-wmm} дано краткое введение 
в задачу верификации методом проверки моделей 
в контексте слабых моделей памяти.
В разделе \ref{sec:genmc} описывается оригинальный алгоритм 
\genmc для модели памяти \RCMM.
В разделе \ref{sec:wmc} описывается разработанный в 
рамках данной диссертации алгоритм \wmc для модели памяти \WkmS.
Наконец, в разделе \ref{sec:wmc-eval} описаны эксперименты 
по измерению производительности алгоритма \wmc и его сравнению с аналогами.

\section{Метод проверки моделей для слабых моделей памяти}
\label{sec:mc-wmm}

Напомним, что \emph{метод проверки моделей} (\emph{model checking}) 
является одним из методов формальной автоматической верификации программ,
целью которого является проверка удовлетворяет ли 
модель программы заданной спецификации. 
\TODO{Упомянуть что рассматриваем только safety свойства.}

Метод проверки моделей с \emph{явным представлением состояний} 
(\emph{explicit-state model checking}) достигает 
этой цели путем явного построения пространства состояний программы 
и перечисления возможных сценариев ее исполнения.
Поскольку количество возможных сценариев исполнения 
растет экспоненциально с ростом программы, 
перечисление всех возможных сценариев исполнения 
на практике не предоставляется возможным. 
Для решения этой проблемы используются различные техники, 
призванные сократить пространство перебора. 

Одной из таких техник является 
\emph{редукция частичного порядка} (\emph{partial order reduction}). 
В основе этой техники лежит наблюдение, что 
порядок выполнения некоторых операций программы 
не имеет значения для конечного результата, 
то есть, данные операции коммутируют. 
Таким образом все сценарии исполнения можно разбить 
на классы эквивалентности, где каждый класс 
можно представить отношением частичного порядка, 
которое упорядочивает только те операции, которые не коммутируют. 
Тогда достаточно рассмотреть только один сценарий исполнения из каждого класса.   

В контексте слабых моделей памяти принято рассматривать 
$\lPORF$-эквивалентность сценариев исполнения%
~\cite{},
то есть эквивалентность с точностью до отношений $\lPO$ и $\lRF$ 
на соответствующих графах сценариев исполнения.
Иногда также рассматривается $\lPORFMO$-эквивалентность, 
то есть эквивалентность с точностью до отношений $\lPO$, $\lRF$ и $\lMO$. 
Таким образом задача проверки моделей в контексте 
слабых моделей памяти сводится к задаче перечисления 
консистентных графов сценариев исполнения заданной программы. 

\section{Алгоритм \genmc для модели \RCMM}
\label{sec:genmc}

Описание алгоритма \genmc. Пример работы алгоритма. 

\section{Алгоритм \wmc для модели \WkmS}
\label{sec:wmc}

Описание модифицированной версии алгоритма \genmc --- \wmc ---
для модели \WkmS. Пример работы алгоритма.
Обсуждение открытых проблем и заделов
для будущей работы в алгоритме. 

\section{Оценка эффективности алгоритма \wmc}
\label{sec:wmc-eval}

Для того чтобы оценить эффективность алгоритма \wmc были 
сформулированы следующие исследовательские вопросы:
\begin{enumerate}

  \item Как часто на практике встречаются гонки с буферизацией операций чтения
    и каковы накладные расходы на их обнаружение?
    Так как модель \WkmS, благодаря свойству \LBRF, присваивает 
    программам свободным от данного типа гонок только \RCMM консистентные сценарии исполнения, 
    это означает, что чем реже такие гонки встречаются на практике, 
    тем ближе производительность алгоритма \wmc 
    будет к производительности оригинального алгоритма \genmc.

  \item Насколько эффективен алгоритм \wmc по сравнению 
    с другими алгоритмами, которые поддерживают 
    модели памяти, сохраняющие синтаксические или семантические зависимости. 

  \item Как изменяется производительность \wmc на синтетических программах, 
    содержащих множество гонок с буферизацией операций чтения. 
    
\end{enumerate}

\paragraph{Инструменты проверки моделей.}

В экспериментах будем сравнивать \wmc со следующими инструментами.

\begin{itemize}

  \item \genmc~\cite{Kokologiannakis:PLDI2019,Kokologiannakis:CAD2021} ---
    это инструмент проверки моделей, выполняющий верификацию в модели памяти \RCMM%
    \footnote{\genmc также может быть адаптирован для поддержки 
    произвольной модели памяти, сохраняющей программный порядок.}, 
    которая относится к классу моделей, сохраняющих программный порядок.  
    Отметим, что в отличие от всех других инструментов, используемых в экспериментах, 
    только \genmc не использует спекулятивное исполнение инструкций 
    ни в каком виде, так как для класса моделей, сохраняющих программный порядок,
    нет необходимости в его использовании для моделирования поведения программы. 
    Поэтому ожидаемо, что \genmc будет показывать 
    лучшее время работы по сравнению со всеми другими инструментами. 
    По этой причине, а также потому, что \wmc изначально разрабатывался 
    на основе \genmc, время работы \genmc в экспериментах 
    используется в качестве базового измерения. 

  \item \hmc~\cite{Kokologiannakis-Vafeiadis:ASPLOS2020} --- 
    это расширение \genmc, поддерживающее модель памяти \IMM
    \footnote{\hmc также может быть адаптирован для поддержки 
    произвольной модели памяти, сохраняющей синтаксические зависимости.},
    которая относится к классу моделей, сохраняющих синтаксические зависимости.  
    Алгоритм, лежащий в основе \hmc, отслеживает синтаксические зависимости между событиями, 
    чтобы предотвратить появление циклов причинно-следственной связи. 

  \item \Nidhugg~\cite{Abdulla-al:TACAS2015,Abdulla-al:CAV2016} --- 
    это инструмент проверки моделей, который, среди прочих, 
    поддерживает модель памяти мультипроцессоров \POWER, 
    относящуюся к классу моделей, сохраняющих синтаксические зависимости.  
    Аналогично \hmc данный инструмент отслеживает синтаксические зависимости между событиями.

  \item \rmem~\cite{RMEM} --- 
    это симулятор для выполнения многопоточных программ с учетом слабых сценариев исполнения. 
    Данный симулятор поддерживает множество моделей памяти различных мультипроцессоров. 
    В рамках данной работы в экспериментах используется режим \PrmARM%
    ~\cite{Pulte-al:PLDI2019}, так как данный режим является 
    наиболее эффективным в инструменте \rmem.
    Режим \PrmARM проводит верификацию в модели памяти \ARMv{8}, 
    которая относится к классу моделей, сохраняющих синтаксические зависимости. 
    При этом для моделирования спекулятивного выполнения инструкций 
    используется механизм обещаний~\cite{Kang-al:POPL17}.  

  \item \CDSChecker~\cite{Norris-Demsky:OOPSLA2013} --- 
    еще один инструмент проверки моделей, выполняющий верификацию 
    в неформально определенной модифицированной версии модели памяти \CMM.
    Данный инструмент также использует механизм обещаний~\cite{Kang-al:POPL17}, 
    чтобы моделировать спекулятивное исполнение и отслеживать
    семантические зависимости между событиями. 
    Таким образом, среди всех перечисленных инструментов,
    только \CDSChecker выполняет верификацию в модели памяти, 
    относящейся к классу моделей, сохраняющих семантические зависимости. 
    Следовательно, данный инструмент наиболее близок по функциональности к \wmc.

\end{itemize}

\paragraph{Конфигурация системы.} 

Все эксперименты проводились на системе Dell PowerEdge M620 blade
с двумя процессорами Intel Xeon E5-2667 v2 (8 ядер, 3.3 GHz)
и 256GB оперативной памяти. Операционная система --- Debian.
Использовалась библиотека \LLVM версии 7.
Также использовались следующие версии сравниваемых инструментов: 
\hmc (v0.5), \genmc (v0.5), \Nidhugg (v0.3), 
коммит с хешем \#da671f7 для \CDSChecker
и коммит с хешем \#85c8130 для \rmem (v0.1). 

Результаты замеров времени работы инструментов 
во всех таблицах в этом разделе приводятся 
в секундах если явно не указано иначе. 
Установленное максимальное ограничение на время работы --- 30 минут.

\subsection*{Оценка частоты появления гонок с буферизацией операции чтения}

Для того чтобы оценить как часто в реалистичных многопоточных
программах встречаются гонки с буферизацией операции чтения
и насколько затратно алгоритму \wmc их обнаружить, 
%% был поставлен следующий эксперимент.
было поставлено два эксперимента. 

В рамках первого эксперимента были рассмотрены 
реализации 13 алгоритмов блокировки из работы%
~\cite{Oberhauser-al:ASPLOS2021},
5 реализаций многопоточной очереди из работы%
~\cite{Kokologiannakis:PLDI2019}
и 10 реализаций многопоточных структур данных из работы%
\footnote{Были рассмотрены только 10 из 43 
тестовых программ из данной работы, 
так как эти программы были написаны на языке C++,
а \genmc поддерживает язык C и только подмножество возможностей языка C++.}. 
~\cite{Ou-Demsky:OOPSLA18}.
Путем запуска \wmc на этих программах была подтверждена гипотеза, 
что гонки с буферизацией операций чтения довольно редко
встречаются на практике: из 28 тестовых программ
только в 2 были найдены гонки данного вида.

%% One of them was due to
%% the porting of a non-C11-compliant queue to C11, while the
%% other was an intentional race part of a lock implementation
%% (\bmark{musl\_lock}), that could not lead to LB behaviors.

В рамках второго эксперимента была рассмотрена 241 многопоточная программа 
из набора тестовых программ инструмента \genmc, 
который включает как небольшие ``лакмусовые тесты''~\cite{Alglave-al:TACAS2011}, 
так и реализации различных многопоточных структур данных.
Данный набор программ был разбит на две группы:
те программы, которые содержат гонки с буферизацией чтения 
(28 программ, название группы LB-racy)
и те, которые не содержат гонок данного типа 
(213 программ, название группы LB-race-free).
Далее было замерено время работы алгоритмов \genmc, \hmc и \wmc на данных программах.  
Результаты замеров представлены в таблице~\ref{tab:overhead}.

\input{Dissertation/table/overhead}

Как можно видеть по второй строке таблицы, 
процесс обнаружения гонок с буферизацией операций чтения 
в алгоритме \wmc приводит к накладным расходам на время работы 
примерно в 25\% процентов по сравнению с временем работы \genmc.
Тем не менее, эти накладные расходы существенно ниже чем 
расходы на поддержание информации о синтаксических зависимостях
в алгоритме \hmc, которые увеличивают время работы \hmc
на программах из второй группы в два раза.  
Можно видеть, что на программах из обоих групп
время работы \wmc существенно меньше времени работы \hmc. 

По результатам этих экспериментов можно сделать вывод, 
что гонки с буферизацией чтения действительно встречаются 
довольно редко в не синтетических многопоточных программах, 
и что затраты на их обнаружения не доминируют 
в суммарном времени работы алгоритма.

%% не приводят к существенному
%% замедлению алгоритма. 

%% Более того, схема с 
%% запуском спекулятивного исполнения только в случае 
%% обнаружения гонок с буферизацией чтения (\wmc) 
%% оказывается более эффективной, чем постоянное отслеживание 
%% синтаксических зависимостей между событиями (\hmc). 

\subsection*{Сравнение алгоритма \wmc с аналогами}

Чтобы сравнить алгоритм \wmc с аналогами было использовано 
два тестовых набора программ.

Первый набор тестовых программ был взят 
из соревнования по верификации программ \SVCOMP~\cite{SVCOMP}, 
а именно из категорий \texttt{pthread} и \texttt{pthread-atomic}.
Тестовые программы были модифицированы путем замены 
обращений к разделяемым переменным на атомарные обращения 
с ослабленным (relaxed) режимом доступа, 
для того чтобы спровоцировать появление гонок 
с буферизацией операций чтения. 
Отметим, что на некоторых программах из данного набора 
инструмент \Nidhugg был исключен из сравнения, так как он не поддерживает 
атомарные инструкции чтения-модификации-записи (\RMW) в модели памяти \POWER. 
Соответствующие ячейки в таблице оставлены пустыми.

Второй набор тестовых программ состоит из 
реализаций различных многопоточных структур данных, 
взятых из тестового набора \CDSChecker~\cite{Norris-Demsky:OOPSLA2013}. 
В данных программах все циклы были развернуты 
на определенную фиксированную глубину, чтобы исключить из сравнения тот фактор, 
поддерживают ли инструменты продвинутые методы рассуждения о циклах или нет. 
В рамках экспериментов с данным тестовым набором инструмент \Nidhugg 
был исключен из сравнения, так как в нем не поддерживаются 
атомарные инструкции чтения-модификации-записи (\RMW) в модели памяти \POWER.
Инструмент \rmem также был исключен из-за сложности портирования 
программ из данного набора в формат входных данных этого инструмента.

Результаты экспериментов для первого и второго 
тестовых наборов представлены в таблицах~\ref{tab:svcomp} 
и~\ref{tab:datastructures} соответственно.

\input{Dissertation/table/svcomp}

Сначала проанализируем данные из таблицы~\ref{tab:svcomp}. 
Можно видеть, что \Nidhugg и \rmem работаю существенно медленнее остальных 
конкурентов почти на всех тестовых программах. 
Это объясняется особенностью используемых этими инструментами алгоритмов.
\Nidhugg выполняет дорогостоящие проверки консистентности
на каждом шаге исполнения программы.
\rmem строит линейный порядок на множестве всех операций записи.

Единственная программа, на которой \Nidhugg показывает 
лучший результат по сравнению с остальными, это \bmark{szymanski}.
Дело в том, что в данной программе используется 
последовательно-согласованные барьеры памяти.
\Nidhugg выполняет проверку последовательно-согласованной
консистентности на каждом шаге исполнения программы, в то время 
как остальные инструменты откладывают эту проверку 
до завершения исследования сценария исполнения. 
В то время как в большинстве случаев выполнение этой дорогостоящей проверки 
на каждом шаге существенно замедляет \Nidhugg, 
в случае программы \bmark{szymanski} это позволяет 
раньше отфильтровать неконсистентные сценарии исполнения 
и таким образом сократить пространство перебора. 

Что касается сравнения с \CDSChecker, то можно видеть,
что этот инструмент опережает \wmc только 
на программах \bmark{reorder} и \bmark{singleton}, 
а на всех остальных программах \CDSChecker работает существенно 
медленнее чем \wmc, и, в некоторых случаях 
(например, \bmark{fib\_bench} и \bmark{sigma}), 
даже превышает заданный лимит времени, в то время как 
\wmc укладывается в этот лимит.
Худшее время работы \CDSChecker объясняется тем, что 
данный инструмент вынужден тратить много времени 
на попытку сертификации неосуществимых обещаний. 
В то же время, свойства \LBRF, помогает \wmc 
рассматривать меньше потенциальных обещаний, 
а свойство \CL помогает быстро проверить 
сертифицируемость оставшихся обещаний.  

Заметим, что на тестовых программах из этого набора 
время работы \hmc также примерно в два раза больше времени работы \genmc, 
как и в случае данных из таблицы~\ref{tab:overhead}.
Это приводит к тому, что на некоторых тестовых программах 
(например, \bmark{sigma} и \bmark{indexer}) \wmc обгоняет \hmc.
Это вновь подтверждает гипотезу, что для программ, 
которые содержат мало гонок c буферизацией операций чтения, 
схема с запуском спекулятивного исполнения только в случае 
обнаружения этих гонок (\wmc) оказывается более эффективной, 
чем постоянное отслеживание синтаксических зависимостей между событиями (\hmc). 

Тем не менее, на программах \bmark{fib\_bench} и \bmark{peterson}
\wmc показывает худшее время по сравнению с \hmc.
Для \bmark{fib\_bench} проблема заключается в том, 
что \wmc вынужден тратить много времени 
на попытку сертификации неосуществимых обещаний, 
это проблема с которой также сталкивается \CDSChecker.
Что касается \bmark{peterson} то здесь проблема 
заключается в самой модели \WkmS --- для 
данной программы эта модель памяти просто допускает 
существенно большее количество слабых сценариев исполнения, 
чем модель \IMM, относительно которой выполняет верификацию \hmc. 

\input{Dissertation/table/realworld}

Результаты экспериментов, приведенные в таблице~\ref{tab:datastructures}
в целом подтверждают приведенные выше наблюдения. 
Время работы \CDSChecker на порядок больше времени 
работы других инструментов на всех тестовых программах, 
более того на 3 из 5 программ \CDSChecker не укладывается 
в заданный лимит времени. Время работы \hmc примерно в
два раза выше чем у \genmc --- замедление вызвано накладными расходами
на поддержание информации о синтаксических зависимостях между событиями.
На программах из этой группы \wmc вновь обходит \hmc, 
так как первые три программы из списка вообще не содержат 
гонок с буферизацией операций чтения, 
а две другие хоть и содержат гонки данного вида, 
обработка этих гонок все равно оказывается 
более эффективной, чем расходы на отслеживание синтаксических зависимостей.

Подводя итоги, можно сделать следующие выводы. 
\wmc оказывается намного более эффективным чем \CDSChecker --- 
единственный инструмент среди аналогов, который 
также выполняет верификацию в модели памяти, сохраняющей семантические зависимости.    
Вместе с тем на многих тестовых программах \wmc также опережает 
и другие инструменты (например, \hmc),
выполняющие верификацию в моделях памяти, 
сохраняющей синтаксические зависимости, даже 
несмотря на то, что этот класс моделей устроен более просто
и, как правило, допускает меньше возможных 
слабых сценариев исполнения чем модель \WkmS.
Это преимущество особенно заметно на программах, 
которые не содержат гонки с буферизацией операций чтения, 
либо содержат малое количество таких гонок. 

Наконец отметим, что \wmc показывает худшую производительность 
по сравнению с другими инструментами на тех тестовых программах, 
которые не используют активно примитивы для синхронизации между потоками, 
такие как барьеры памяти или более сильные режимы доступа к атомарным переменным. 
К таким программам относится, например, тестовая программа \bmark{peterson}, 
реализующая алгоритм блокировки Петерсона. 
Подобные программы используют исключительно только ослабленные (relaxed)
режимы обращения к атомарным переменным.
Эта ситуация крайне нехарактерная для большинства 
практические значимых многопоточных программ, 
так как использование только ослабленных обращений к памяти
дает крайне мало гарантий о поведении программ. 
В остальных случаях \wmc показывает производительность 
лучшую по отношению к другим инструментам
и сравнимую с производительностью исходного алгоритма~\genmc.

\subsection*{Время работы \wmc на синтетических программах}

Также была выполнения оценка времени работы \wmc 
на искусственных программах, содержащих множество 
гонок с буферизацией операций чтения. 
Хотя программы, используемые в данном эксперименте, 
редко встречаются на практике, интерес представляет 
оценка того, как \wmc ведет себя в таких случаях.

Результаты эксперимента приведены в таблице~\ref{tab:lb}.
Первая колонка данной таблицы содержит название тестовой программы. 
Вторая колонка --- количество уникальных сценариев исполнения, 
исследованных \wmc. Третья колонка --- процент повторяющихся
сценариев, посещенных алгоритмом несколько раз, от 
количества уникальных сценариев. 
Последняя колонка показывает процент блокированных 
сценариев --- то есть тех сценариев, которые 
были отброшены во время работы алгоритма \wmc 
из-за невозможности сертифицировать все сделанные обещания.

\input{Dissertation/table/lb}

Кратко опишем тестовые программы из данного эксперимента. 
Программы \bmark{LB+ctrl(N)} и \bmark{LB+data(N)}
являются аналогом программы \ref{ex:lb-nodep} 
из раздела \cref{sec:models-classes},
за исключением того, что в этих программах 
$\lPORF$ цикл охватывает \texttt{N} потоков.
Также, в программе \bmark{LB+ctrl(N)} используются зависимости 
по потоку управления, а не зависимости по данным как в \bmark{LB+data(N)}.
Тестовая программа \bmark{LB-nodep(N)} является аналогом 
программы \ref{ex:lb-spec} из раздела \ref{sec:models-requirements}, 
за исключением того, что в этой программе 
$\lPORF$ цикл также охватывает \texttt{N} потоков.
Наконец, программа \bmark{LB-pairs(N)} содержит \texttt{N}
независимых пар потоков, где каждая пара образует 
подпрограмму, аналогичную \ref{ex:lb-spec}.

Алгоритм \wmc исследует одинаковое количество уникальных сценариев
исполнения для всех программ, за исключением \bmark{LB+ctrl}.
В случае последней наличие зависимостей по управлению 
предотвращает появление большего количества слабых 
сценариев исполнения, содержащих $\lPORF$ циклы. 
За исключением программы \bmark{LB-pairs} 
количество повторяющихся и заблокированных сценариев исполнения 
остается очень маленьким. Однако для \bmark{LB-pairs}
количество повторяющихся сценариев исполнения 
в несколько раз превышает количество уникальных сценариев, 
а количество заблокированных сценариев составляет одну треть 
от количества уникальных. 
В подобных случаях \wmc может потребоваться 
сохранять информацию о всех сгенерированных сценариев исполнения, 
чтобы избежать необходимости их повторного посещения, 
однако реализация данной стратегии приведет 
к кратному увеличению потребляемой памяти.  
